{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIK9v7TqQxSX"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVKGEmFjJIet"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.distributions as dist\n",
        "from torch.special import log_ndtr, ndtr\n",
        "from torch.nn.functional import logsigmoid\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "import math\n",
        "import time\n",
        "import copy\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW1ZXZ0kPxHz"
      },
      "source": [
        "## Logistic LL: Original functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wehSSshiPMZf"
      },
      "outputs": [],
      "source": [
        "def KL_mvn(m, S, mu, Sig):\n",
        "    \"\"\"\n",
        "    Can also be computed via:\n",
        "        mvn1 = dist.MultivariateNormal(m, S)\n",
        "        mvn2 = dist.MultivariateNormal(mu, Sig)\n",
        "        dist.kl.kl_divergence(mvn1, mvn2)\n",
        "    \"\"\"\n",
        "    p = m.size()[0]\n",
        "    res = 0.5 * (torch.logdet(Sig) - torch.logdet(S) -  p +\n",
        "                 torch.trace(Sig.inverse() @ S) +\n",
        "                 (mu - m).t() @ Sig.inverse() @ (mu - m))\n",
        "    return res\n",
        "\n",
        "\n",
        "def KL(m, s, mu, sig):\n",
        "    \"\"\"\n",
        "    Compute the KL divergence between two Gaussians\n",
        "    :param m: mean of variational distribution\n",
        "    :param s: standard deviation of variational distribution\n",
        "    :param mu: mean of prior\n",
        "    :parma sig: standard deviation of prior\n",
        "    :return: KL divergence\n",
        "    \"\"\"\n",
        "    res = torch.log(sig / s) + 0.5 * ((s ** 2 + (m - mu) ** 2) / sig ** 2 - 1)\n",
        "    return torch.sum(res)\n",
        "\n",
        "\n",
        "def KL_MC(m, s, mu, sig):\n",
        "    \"\"\"\n",
        "    Compute the KL divergence between two Gaussians with monte carlo\n",
        "    :param m: mean of variational distribution\n",
        "    :param s: standard deviation of variational distribution\n",
        "    :param mu: mean of prior\n",
        "    :parma sig: standard deviation of prior\n",
        "    :return: KL divergence\n",
        "    \"\"\"\n",
        "    d1 = dist.Normal(m, s)\n",
        "    d2 = dist.Normal(mu, sig)\n",
        "\n",
        "    x = d1.sample((1000,))\n",
        "    return torch.mean(torch.sum(d1.log_prob(x) - d2.log_prob(x), 1))\n",
        "\n",
        "\n",
        "def ELL_TB(m, s, y, X, l_max = 10.0, XX=None):\n",
        "    \"\"\"\n",
        "    Compute the expected negative log-likelihood\n",
        "    :return: ELL\n",
        "    \"\"\"\n",
        "    M = X @ m\n",
        "\n",
        "    if XX is None:\n",
        "        S = torch.sum(X ** 2 * s ** 2, dim=1)\n",
        "    else:\n",
        "        S = torch.sum(XX * s ** 2, dim=1)\n",
        "\n",
        "    S = torch.sqrt(S)\n",
        "\n",
        "    l = torch.arange(1.0, l_max*2, 1.0, requires_grad=False, dtype=torch.float64)\n",
        "\n",
        "    M = M.unsqueeze(1)\n",
        "    S = S.unsqueeze(1)\n",
        "    l = l.unsqueeze(0)\n",
        "\n",
        "\n",
        "    res =  \\\n",
        "        torch.dot(- y, X @ m) + \\\n",
        "        torch.sum(\n",
        "            S / math.sqrt(2 * torch.pi) * torch.exp(- 0.5 * M**2 / S**2) + \\\n",
        "            M * ndtr(M / S)\n",
        "        ) + \\\n",
        "        torch.sum(\n",
        "            (-1.0)**(l - 1.0) / l * (\n",
        "                torch.exp( M @ l + 0.5 * S**2 @ (l ** 2) + log_ndtr(-M / S - S @ l)) + \\\n",
        "                torch.exp(-M @ l + 0.5 * S**2 @ (l ** 2) + log_ndtr( M / S - S @ l))\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "\n",
        "def ELL_TB_mvn(m, S, y, X, l_max = 10.0):\n",
        "    \"\"\"\n",
        "    Compute the expected negative log-likelihood\n",
        "    :return: ELL\n",
        "    \"\"\"\n",
        "    M = X @ m\n",
        "    # this might be faster\n",
        "    # S = (X.unsqueeze(1) @ S @ X.unsqueeze(2)).squeeze()\n",
        "\n",
        "    try:\n",
        "        U = torch.linalg.cholesky(S)\n",
        "        S = torch.sum((X @ U) ** 2, dim=1)\n",
        "    except:\n",
        "        S = torch.sum(X * (S @ X.t()).t(), dim=1)\n",
        "\n",
        "    S = torch.sqrt(S)\n",
        "\n",
        "    l = torch.arange(1.0, l_max*2, 1.0, requires_grad=False, dtype=torch.float64)\n",
        "\n",
        "    M = M.unsqueeze(1)\n",
        "    S = S.unsqueeze(1)\n",
        "    l = l.unsqueeze(0)\n",
        "\n",
        "    res =  \\\n",
        "        torch.dot(- y, M.squeeze()) + \\\n",
        "        torch.sum(\n",
        "            S / math.sqrt(2 * torch.pi) * torch.exp(- 0.5 * M**2 / S**2) + \\\n",
        "            M * ndtr(M / S)\n",
        "        ) + \\\n",
        "        torch.sum(\n",
        "            (-1.0)**(l - 1.0) / l * (\n",
        "                torch.exp( M @ l + 0.5 * S**2 @ (l ** 2) + log_ndtr(-M / S - S @ l)) + \\\n",
        "                torch.exp(-M @ l + 0.5 * S**2 @ (l ** 2) + log_ndtr( M / S - S @ l))\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def ELL_MC(m, s, y, X, n_samples=1000):\n",
        "    \"\"\"\n",
        "    Compute the expected negative log-likelihood with monte carlo\n",
        "    :return: ELL\n",
        "    \"\"\"\n",
        "    # print(f\"ELL_MC: m={m} s={s}\")\n",
        "\n",
        "    M = X @ m\n",
        "    # S = torch.sqrt(X ** 2 @ s ** 2)\n",
        "    S = torch.sum(X ** 2 * s ** 2, dim=1)\n",
        "    S = torch.sqrt(S)\n",
        "\n",
        "    norm = dist.Normal(torch.zeros_like(M), torch.ones_like(S))\n",
        "    samp = norm.sample((n_samples, ))\n",
        "    samp = M + S * samp\n",
        "\n",
        "    res =  torch.dot( - y, M) + \\\n",
        "        torch.sum(torch.mean(torch.log1p(torch.exp(samp)), 0))\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def ELL_MC_mvn(m, S, y, X, n_samples=1000):\n",
        "    \"\"\"\n",
        "    Compute the expected negative log-likelihood with monte carlo\n",
        "    :return: ELL\n",
        "    \"\"\"\n",
        "    M = X @ m\n",
        "    # S = torch.diag(X @ S @ X.t())\n",
        "\n",
        "    try:\n",
        "        U = torch.linalg.cholesky(S)\n",
        "        S = torch.sum((X @ U) ** 2, dim=1)\n",
        "    except:\n",
        "        S = torch.sum(X * (S @ X.t()).t(), dim=1)\n",
        "\n",
        "    S = torch.sqrt(S)\n",
        "\n",
        "    norm = dist.Normal(torch.zeros_like(M), torch.ones_like(S))\n",
        "    samp = norm.sample((n_samples, ))\n",
        "    samp = M + S * samp\n",
        "\n",
        "    res =  torch.dot( - y, M) + \\\n",
        "        torch.sum(torch.mean(torch.log1p(torch.exp(samp)), 0))\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def ELL_Jak(m, s, t, y, X):\n",
        "    \"\"\"\n",
        "    Compute the expected negative log-likelihood using the bound introduced\n",
        "    by Jaakkola and Jordan (2000)\n",
        "    :return: ELL\n",
        "    \"\"\"\n",
        "    M = X @ m\n",
        "    a_t = (torch.sigmoid(t) - 0.5) / t\n",
        "    S = torch.diag(s**2) + torch.outer(m, m)\n",
        "\n",
        "    try:\n",
        "        U = torch.linalg.cholesky(S)\n",
        "        B = a_t * torch.sum((X @ U) ** 2, dim=1)\n",
        "    except:\n",
        "        B = a_t * torch.sum(X * (S @ X.t()).t(), dim=1)\n",
        "\n",
        "    res = - torch.dot(y, M) - torch.sum(logsigmoid(t)) + \\\n",
        "        0.5 * torch.sum(M + t) + 0.5 * torch.sum(B)   - \\\n",
        "        0.5 * torch.sum(a_t * t ** 2)\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def ELL_Jak_mvn(m, S, t, y, X):\n",
        "    \"\"\"\n",
        "    Compute the expected negative log-likelihood using the bound introduced\n",
        "    by Jaakkola and Jordan (2000)\n",
        "    :return: ELL\n",
        "    \"\"\"\n",
        "    M = X @ m\n",
        "    a_t = (torch.sigmoid(t) - 0.5) / t\n",
        "    SS = S + torch.outer(m, m)\n",
        "\n",
        "    try:\n",
        "        U = torch.linalg.cholesky(SS)\n",
        "        B = a_t * torch.sum((X @ U) ** 2, dim=1)\n",
        "    except:\n",
        "        B = a_t * torch.sum(X * (SS @ X.t()).t(), dim=1)\n",
        "\n",
        "    res = - torch.dot(y, M) - torch.sum(logsigmoid(t)) + \\\n",
        "        0.5 * torch.sum(M + t) + 0.5 * torch.sum(B)   - \\\n",
        "        0.5 * torch.sum(a_t * t ** 2)\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def ELBO_TB(m, u, y, X, mu, sig, l_max = 10.0, XX=None):\n",
        "    \"\"\"\n",
        "    Compute the negative of the ELBO\n",
        "    :return: ELBO\n",
        "    \"\"\"\n",
        "    s = torch.exp(u)\n",
        "    return ELL_TB(m, s, y, X, l_max=l_max, XX=XX) + KL(m, s, mu, sig)\n",
        "\n",
        "\n",
        "def ELBO_TB_mvn(m, u, y, X, mu, Sig, l_max = 10.0):\n",
        "    \"\"\"\n",
        "    Compute the negative of the ELBO\n",
        "    :return: ELBO\n",
        "    \"\"\"\n",
        "    p = Sig.size()[0]\n",
        "    L = torch.zeros(p, p, dtype=torch.double)\n",
        "    L[torch.tril_indices(p, p, 0).tolist()] = u\n",
        "    S = L.t() @ L\n",
        "\n",
        "    return ELL_TB_mvn(m, S, y, X, l_max=l_max) + KL_mvn(m, S, mu, Sig)\n",
        "\n",
        "\n",
        "def ELBO_MC(m, u, y, X, mu, sig, n_samples=1000):\n",
        "    \"\"\"\n",
        "    Compute the negative of the ELBO\n",
        "    :return: ELBO\n",
        "    \"\"\"\n",
        "    s = torch.exp(u)\n",
        "    return ELL_MC(m, s, y, X, n_samples) + KL(m, s, mu, sig)\n",
        "\n",
        "\n",
        "def ELBO_MC_mvn(m, u, y, X, mu, Sig, n_samples=1000):\n",
        "    \"\"\"\n",
        "    Compute the negative of the ELBO\n",
        "    :return: ELBO\n",
        "    \"\"\"\n",
        "    p = Sig.size()[0]\n",
        "    L = torch.zeros(p, p, dtype=torch.double)\n",
        "    L[torch.tril_indices(p, p, 0).tolist()] = u\n",
        "    S = L.t() @ L\n",
        "\n",
        "    return ELL_MC_mvn(m, S, y, X, n_samples) + KL_mvn(m, S, mu, Sig)\n",
        "\n",
        "\n",
        "def ELBO_Jak(m, s, t, y, X, mu, sig):\n",
        "    \"\"\"\n",
        "    Compute the negative of the ELBO using the bound introduced by\n",
        "    Jaakkola and Jordan (2000)\n",
        "    :return: ELBO\n",
        "    \"\"\"\n",
        "    return ELL_Jak(m, s, t, y, X) + KL(m, s, mu, sig)\n",
        "\n",
        "\n",
        "def ELBO_Jak_mvn(m, S, t, y, X, mu, Sig, cov=None):\n",
        "    \"\"\"\n",
        "    Compute the negative of the ELBO using the bound introduced by\n",
        "    Jaakkola and Jordan (2000)\n",
        "    :return: ELBO\n",
        "    \"\"\"\n",
        "    return ELL_Jak_mvn(m, S, t, y, X) + KL_mvn(m, S, mu, Sig)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG3O7vgBBYXY"
      },
      "source": [
        "## Logistic LL: Multi-head functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0QnUfs8BTCh"
      },
      "outputs": [],
      "source": [
        "def KL_MH(m_list, s_list, mu_list, sig_list):\n",
        "    total_KL = sum(KL(m, s, mu, sig) for m, s, mu, sig in zip(m_list, s_list, mu_list, sig_list))\n",
        "    return total_KL\n",
        "\n",
        "def KL_mvn_MH(m_list, S_list, mu_list, Sig_list):\n",
        "    total_KL = sum(KL_mvn(m, S, mu, Sig) for m, S, mu, Sig in zip(m_list, S_list, mu_list, Sig_list))\n",
        "    return total_KL\n",
        "\n",
        "def ELL_TB_MH(m_list, s_list, y_list, X, l_max=10.0, XX=None):\n",
        "    total_ELL = sum(ELL_TB(m, s, y, X, l_max=l_max, XX=XX) for m, s, y in zip(m_list, s_list, y_list))\n",
        "    return total_ELL\n",
        "\n",
        "def ELL_TB_mvn_MH(m_list, S_list, y_list, X, l_max=10.0):\n",
        "    total_ELL = sum(ELL_TB_mvn(m, S, y, X, l_max=l_max) for m, S, y in zip(m_list, S_list, y_list))\n",
        "    return total_ELL\n",
        "\n",
        "def ELL_MC_MH(m_list, s_list, y_list, X, n_samples=1000):\n",
        "    total_ELL = sum(ELL_MC(m, s, y, X, n_samples=n_samples) for m, s, y in zip(m_list, s_list, y_list))\n",
        "    return total_ELL\n",
        "\n",
        "def ELL_MC_mvn_MH(m_list, S_list, y_list, X, n_samples=1000):\n",
        "    total_ELL = sum(ELL_MC_mvn(m, S, y, X, n_samples=n_samples) for m, S, y in zip(m_list, S_list, y_list))\n",
        "    return total_ELL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4o5x5Y3Bke-"
      },
      "source": [
        "## Base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFgSP12UvhVx"
      },
      "outputs": [],
      "source": [
        "class LLModel:\n",
        "\n",
        "    def __init__(self, p, K, beta=1.0, intercept=False, backbone=None, seed=1):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        ----------\n",
        "            p : int\n",
        "                Dimensionality of the input features after processing by the backbone network.\n",
        "            K : int\n",
        "                Number of outputs (labels).\n",
        "        \"\"\"\n",
        "        print(f\"[LLModel] beta={beta} input_dim={p} output_dim={K} intercept={intercept}\")\n",
        "        torch.manual_seed(seed)\n",
        "        self.intercept = intercept\n",
        "        if intercept:\n",
        "            p += 1\n",
        "        self.p = p\n",
        "        self.K = K\n",
        "        self.backbone = backbone\n",
        "        self.beta = beta\n",
        "        self.seed = seed\n",
        "\n",
        "        self.params = []\n",
        "        return p\n",
        "\n",
        "    def process(self, X_batch):\n",
        "        if self.backbone is not None:\n",
        "            X_processed = self.backbone(X_batch)\n",
        "        else:\n",
        "            X_processed = X_batch\n",
        "\n",
        "        if self.intercept:\n",
        "            X_processed = torch.cat((torch.ones(X_processed.size()[0], 1), X_processed), 1)\n",
        "        return X_processed\n",
        "\n",
        "    def train_loss(self, X_batch, y_batch, data_size=None, verbose=False):\n",
        "        raise ValueError(\"[LLModel] train_loss not implemented\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        raise ValueError(\"[LLModel] predict not implemented\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctJI_9bOuO73"
      },
      "source": [
        "## Sigmoid-likelihood model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey8HNYQOQWxz"
      },
      "outputs": [],
      "source": [
        "class LogisticVI(LLModel):\n",
        "    \"\"\"\n",
        "    Variational Inference for Logistic Regression with Multiple Outputs.\n",
        "\n",
        "    This class implements variational inference for logistic regression with support for multiple outputs (multi-label classification).\n",
        "    It uses the original functions for computing the KL divergence and expected negative log-likelihood, and builds multihead versions by calling these functions.\n",
        "\n",
        "    The class assumes that the data loader and training loop are handled externally.\n",
        "    It provides methods to compute the ELBO and perform optimization steps given batches of data.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    p : int\n",
        "        Dimensionality of the input features after processing by the backbone network.\n",
        "    K : int\n",
        "        Number of outputs (labels).\n",
        "    method : int, optional\n",
        "        Method to use for approximating the ELBO:\n",
        "        - 0: Proposed bound, diagonal covariance variational family.\n",
        "        - 1: Proposed bound, full covariance variational family.\n",
        "        - 4: Monte Carlo, diagonal covariance variational family.\n",
        "        - 5: Monte Carlo, full covariance variational family.\n",
        "        Default is 0.\n",
        "    mu : torch.Tensor, optional\n",
        "        Prior means for each output. Shape (p, K).\n",
        "    sig : torch.Tensor, optional\n",
        "        Prior standard deviations for each output. Shape (p, K).\n",
        "    Sig : list of torch.Tensor, optional\n",
        "        Prior covariance matrices for each output. List of K tensors, each of shape (p, p).\n",
        "    m_init : torch.Tensor, optional\n",
        "        Initial means of the variational distributions. Shape (p, K).\n",
        "    s_init : torch.Tensor, optional\n",
        "        Initial standard deviations (or lower-triangular parameters) of the variational distributions. Shape depends on method.\n",
        "    l_max : float, optional\n",
        "        Maximum value of l for the proposed bound. Default is 12.0.\n",
        "    adaptive_l : bool, optional\n",
        "        Whether to adaptively increase l during training. Default is False.\n",
        "    n_samples : int, optional\n",
        "        Number of samples for Monte Carlo estimation. Default is 500.\n",
        "    seed : int, optional\n",
        "        Random seed for reproducibility. Default is 1.\n",
        "    backbone : torch.nn.Module, optional\n",
        "        Backbone network to transform input features.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p, K, method=0, beta=1.0, intercept=False,\n",
        "                 mu=None, sig=None, Sig=None, m_init=None, s_init=None,\n",
        "                 l_max=12.0, adaptive_l=False, n_samples=500, seed=1, backbone=None):\n",
        "        p = super().__init__(p, K, beta=beta, intercept=intercept, backbone=backbone, seed=seed)\n",
        "\n",
        "        self.method = method\n",
        "        self.l_max = l_max\n",
        "        self.adaptive_l = adaptive_l\n",
        "        self.n_samples = n_samples\n",
        "\n",
        "        # Initialize prior parameters\n",
        "        if mu is None:\n",
        "            self.mu_list = [torch.zeros(p, dtype=torch.double) for _ in range(K)]\n",
        "        else:\n",
        "            self.mu_list = [mu[:, k] for k in range(K)]\n",
        "\n",
        "        if sig is None:\n",
        "            self.sig_list = [torch.ones(p, dtype=torch.double) for _ in range(K)]\n",
        "        else:\n",
        "            self.sig_list = [sig[:, k] for k in range(K)]\n",
        "\n",
        "        if Sig is None:\n",
        "            self.Sig_list = [torch.eye(p, dtype=torch.double) for _ in range(K)]\n",
        "        else:\n",
        "            self.Sig_list = Sig  # List of K covariance matrices of shape (p, p)\n",
        "\n",
        "        # Initialize variational parameters\n",
        "        if m_init is None:\n",
        "            self.m_list = [torch.randn(p, dtype=torch.double) for _ in range(K)]\n",
        "        else:\n",
        "            self.m_list = [m_init[:, k] for k in range(K)]\n",
        "\n",
        "        if s_init is None:\n",
        "            if method in [0, 4]:\n",
        "                self.u_list = [torch.tensor([-1.0] * p, dtype=torch.double) for _ in range(K)]\n",
        "                self.s_list = [torch.exp(u) for u in self.u_list]\n",
        "            elif method in [1, 5]:\n",
        "                self.u_list = []\n",
        "                for _ in range(K):\n",
        "                    u = torch.ones(int(p * (p + 1) / 2), dtype=torch.double) * (1.0 / p)\n",
        "                    u.requires_grad = True\n",
        "                    self.u_list.append(u)\n",
        "        else:\n",
        "            if method in [0, 4]:\n",
        "                self.s_list = [s_init[:, k] for k in range(K)]\n",
        "                self.u_list = [torch.log(s) for s in self.s_list]\n",
        "            elif method in [1, 5]:\n",
        "                self.u_list = s_init  # Should be list of u tensors for each output\n",
        "\n",
        "        # Set requires_grad=True for variational parameters\n",
        "        for m in self.m_list:\n",
        "            m.requires_grad = True\n",
        "        for u in self.u_list:\n",
        "            u.requires_grad = True\n",
        "\n",
        "        # Collect parameters for optimization\n",
        "        self.params = list(self.m_list) + list(self.u_list)\n",
        "        if self.backbone is not None:\n",
        "            self.params += list(self.backbone.parameters())\n",
        "\n",
        "        # Initialize l_terms for adaptive l\n",
        "        if adaptive_l:\n",
        "            self.l_terms = float(int(l_max / 2))\n",
        "        else:\n",
        "            self.l_terms = l_max\n",
        "\n",
        "    def train_loss(self, X_batch, y_batch, data_size=None, verbose=False):\n",
        "        data_size = data_size or X_batch.shape[0]\n",
        "        return -self.compute_ELBO(X_batch, y_batch, data_size, verbose=verbose)\n",
        "\n",
        "    def compute_ELBO(self, X_batch, y_batch, data_size, verbose=False):\n",
        "        \"\"\"\n",
        "        Compute the Evidence Lower Bound (ELBO) for a batch of data.\n",
        "\n",
        "        Parameters:\n",
        "        ----------\n",
        "        X_batch : torch.Tensor\n",
        "            Batch of input data. Shape (batch_size, input_dim).\n",
        "        y_batch : torch.Tensor\n",
        "            Batch of target variables. Shape (batch_size, K).\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "        ELBO : torch.Tensor\n",
        "            The computed ELBO for the batch.\n",
        "        \"\"\"\n",
        "        X_processed = self.process(X_batch)\n",
        "        batch_size = X_batch.shape[0]\n",
        "\n",
        "        # Prepare lists for variational parameters and priors\n",
        "        m_list = self.m_list\n",
        "        mu_list = self.mu_list\n",
        "        y_list = [y_batch[:, k] for k in range(self.K)]\n",
        "\n",
        "        if self.method in [0, 4]:\n",
        "            s_list = [torch.exp(u) for u in self.u_list]\n",
        "            sig_list = self.sig_list\n",
        "\n",
        "            if self.method == 0:\n",
        "                likelihood = -ELL_TB_MH(m_list, s_list, y_list, X_processed, l_max=self.l_terms)\n",
        "                KL_div = KL_MH(m_list, s_list, mu_list, sig_list)\n",
        "            else:\n",
        "                likelihood = -ELL_MC_MH(m_list, s_list, y_list, X_processed, n_samples=self.n_samples)\n",
        "                KL_div = KL_MH(m_list, s_list, mu_list, sig_list)\n",
        "\n",
        "        elif self.method in [1, 5]:\n",
        "            L_list = []\n",
        "            for u in self.u_list:\n",
        "                L = torch.zeros(self.p, self.p, dtype=torch.double)\n",
        "                tril_indices = torch.tril_indices(self.p, self.p, 0)\n",
        "                L[tril_indices[0], tril_indices[1]] = u\n",
        "                L_list.append(L)\n",
        "\n",
        "            S_list = [L @ L.t() for L in L_list]\n",
        "            if self.method == 1:\n",
        "                likelihood = -ELL_TB_mvn_MH(m_list, S_list, y_list, X_processed, l_max=self.l_terms)\n",
        "                KL_div = KL_mvn_MH(m_list, S_list, mu_list, self.Sig_list)\n",
        "            else:\n",
        "                likelihood = -ELL_MC_mvn_MH(m_list, S_list, y_list, X_processed, n_samples=self.n_samples)\n",
        "                KL_div = KL_mvn_MH(m_list, S_list, mu_list, self.Sig_list)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Method not recognized\")\n",
        "\n",
        "        mean_log_lik = likelihood/batch_size\n",
        "        mean_kl_div = KL_div/data_size\n",
        "        ELBO = mean_log_lik - self.beta*mean_kl_div\n",
        "        if verbose:\n",
        "            print(f\"ELBO={ELBO:.2f} mean_log_lik={mean_log_lik:.2f} mean_kl_div={mean_kl_div:.2f}\")\n",
        "        return ELBO\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict probabilities for each output given input data.\n",
        "\n",
        "        Parameters:\n",
        "        ----------\n",
        "        X : torch.Tensor\n",
        "            Input data. Shape (n_samples, input_dim).\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "        preds : torch.Tensor\n",
        "            Predicted probabilities for each output. Shape (n_samples, K).\n",
        "        \"\"\"\n",
        "        X_processed = self.process(X)\n",
        "\n",
        "        preds = []\n",
        "        for m in self.m_list:\n",
        "            pred = torch.sigmoid(X_processed @ m)\n",
        "            preds.append(pred.unsqueeze(1))\n",
        "\n",
        "        preds = torch.cat(preds, dim=1)  # Shape: (n_samples, K)\n",
        "        return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H15Bip-Bnzz"
      },
      "source": [
        "## Sigmoid Deterministic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEEjURs3uuA3"
      },
      "outputs": [],
      "source": [
        "class LogisticPointwise(LLModel):\n",
        "\n",
        "    def __init__(self, p, K, beta=1.0, intercept=False, seed=1, backbone=None,\n",
        "                 m_init=None,\n",
        "                 mu=None, Sig=None):\n",
        "        p = super().__init__(p, K, beta=beta, intercept=intercept, backbone=backbone, seed=seed)\n",
        "\n",
        "        # Initialize prior parameters\n",
        "        if mu is None:\n",
        "            self.mu_list = [torch.zeros(p, dtype=torch.double) for _ in range(K)]\n",
        "        else:\n",
        "            self.mu_list = [mu[:, k] for k in range(K)]\n",
        "\n",
        "        if Sig is None:\n",
        "            self.Sig_list = [torch.eye(p, dtype=torch.double) for _ in range(K)]\n",
        "        else:\n",
        "            self.Sig_list = Sig  # List of K covariance matrices of shape (p, p)\n",
        "\n",
        "        # Initialize variational parameters\n",
        "        if m_init is None:\n",
        "            self.m_list = [torch.randn(p, dtype=torch.double) for _ in range(K)]\n",
        "        else:\n",
        "            self.m_list = [m_init[:, k] for k in range(K)]\n",
        "\n",
        "        # Set requires_grad=True for variational parameters\n",
        "        for m in self.m_list:\n",
        "            m.requires_grad = True\n",
        "\n",
        "        # Collect parameters for optimization\n",
        "        self.params = list(self.m_list)\n",
        "        if self.backbone is not None:\n",
        "            self.params += list(self.backbone.parameters())\n",
        "\n",
        "    def train_loss(self, X_batch, y_batch, data_size=None, verbose=False):\n",
        "        data_size = data_size or X_batch.shape[0]\n",
        "\n",
        "        preds = self.predict(X_batch)\n",
        "        assert preds.shape == y_batch.shape, f\"preds.shape={preds.shape} != y_batch.shape={y_batch.shape}\"\n",
        "        loss = nn.BCELoss(reduction='mean')\n",
        "        mean_bce = loss(preds, y_batch)\n",
        "        mean_reg = self.regularization() / data_size\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"mean_bce_loss={mean_bce:.2f}  mean_reg={mean_reg:.2f}\")\n",
        "\n",
        "        return mean_bce + self.beta * mean_reg\n",
        "\n",
        "    def regularization(self):\n",
        "        log_prob = 0.\n",
        "        for m, prior_mu, prior_Sig in zip(self.m_list, self.mu_list, self.Sig_list):\n",
        "            # simple prior distribution\n",
        "            d = torch.distributions.MultivariateNormal(loc=prior_mu, covariance_matrix=prior_Sig)\n",
        "            log_prob += d.log_prob(m)\n",
        "        return -log_prob\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict probabilities for each output given input data.\n",
        "\n",
        "        Parameters:\n",
        "        ----------\n",
        "        X : torch.Tensor\n",
        "            Input data. Shape (n_samples, input_dim).\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "        preds : torch.Tensor\n",
        "            Predicted probabilities for each output. Shape (n_samples, K).\n",
        "        \"\"\"\n",
        "        X_processed = self.process(X)\n",
        "\n",
        "        preds = []\n",
        "        for m in self.m_list:\n",
        "            pred = torch.sigmoid(X_processed @ m)\n",
        "            preds.append(pred.unsqueeze(1))\n",
        "\n",
        "        preds = torch.cat(preds, dim=1)  # Shape: (n_samples, K)\n",
        "        return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wcrPH7nCDKB",
        "outputId": "409041c9-d455-41a4-9d12-bf4ba1db3e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vbll\n",
            "  Downloading vbll-0.2.6-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting fannypack>=0.0.25 (from vbll)\n",
            "  Downloading fannypack-0.0.25-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from vbll) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from vbll) (2.5.1+cu121)\n",
            "Collecting argcomplete (from fannypack>=0.0.25->vbll)\n",
            "  Downloading argcomplete-3.5.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting beautifultable>=1.0.0 (from fannypack>=0.0.25->vbll)\n",
            "  Downloading beautifultable-1.1.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting dill (from fannypack>=0.0.25->vbll)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from fannypack>=0.0.25->vbll) (3.12.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from fannypack>=0.0.25->vbll) (2.18.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fannypack>=0.0.25->vbll) (6.0.2)\n",
            "Collecting simple-term-menu (from fannypack>=0.0.25->vbll)\n",
            "  Downloading simple_term_menu-1.6.4-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from fannypack>=0.0.25->vbll) (2.17.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fannypack>=0.0.25->vbll) (2.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fannypack>=0.0.25->vbll) (4.66.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fannypack>=0.0.25->vbll) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->vbll) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->vbll) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->vbll) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->vbll) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->vbll) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->vbll) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6.0->vbll) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from beautifultable>=1.0.0->fannypack>=0.0.25->vbll) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->vbll) (3.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->fannypack>=0.0.25->vbll) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->fannypack>=0.0.25->vbll) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->fannypack>=0.0.25->vbll) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard->fannypack>=0.0.25->vbll) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->fannypack>=0.0.25->vbll) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->fannypack>=0.0.25->vbll) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->fannypack>=0.0.25->vbll) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->fannypack>=0.0.25->vbll) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->fannypack>=0.0.25->vbll) (3.1.3)\n",
            "Downloading vbll-0.2.6-py3-none-any.whl (13 kB)\n",
            "Downloading fannypack-0.0.25-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifultable-1.1.0-py2.py3-none-any.whl (28 kB)\n",
            "Downloading argcomplete-3.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simple_term_menu-1.6.4-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: simple-term-menu, dill, beautifultable, argcomplete, fannypack, vbll\n",
            "Successfully installed argcomplete-3.5.1 beautifultable-1.1.0 dill-0.3.9 fannypack-0.0.25 simple-term-menu-1.6.4 vbll-0.2.6\n"
          ]
        }
      ],
      "source": [
        "!pip install vbll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ywwVIC8CPxc"
      },
      "outputs": [],
      "source": [
        "import vbll\n",
        "\n",
        "\n",
        "class VBLLVI(LLModel):\n",
        "\n",
        "    def __init__(self, p, K, vbll_cfg, intercept=False, seed=1, backbone=None):\n",
        "        p = super().__init__(p, K, intercept=intercept, backbone=backbone, seed=seed)\n",
        "        self.vbll_cfg = vbll_cfg\n",
        "\n",
        "        self.heads = [self.make_output_layer(num_hidden=p, num_classes=2) for k in range(K)]\n",
        "\n",
        "        # Collect parameters for optimization\n",
        "        self.params = []\n",
        "        if self.backbone is not None:\n",
        "            self.params += list(self.backbone.parameters())\n",
        "        for head in self.heads:\n",
        "            self.params += list(head.parameters())\n",
        "\n",
        "    def make_output_layer(self, **kwargs):\n",
        "        if self.vbll_cfg.TYPE == \"disc\":\n",
        "            return self._make_disc_vbll_layer(cfg=self.vbll_cfg, **kwargs).double()\n",
        "\n",
        "        elif self.vbll_cfg.TYPE == \"gen\":\n",
        "            return self._make_gen_vbll_layer(cfg=self.vbll_cfg, **kwargs).double()\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown VBLL type={self.vbll_cfg.TYPE}!\")\n",
        "\n",
        "    def _make_disc_vbll_layer(self, num_hidden, num_classes, cfg):\n",
        "        \"\"\" VBLL Discriminative classification head. \"\"\"\n",
        "        return vbll.DiscClassification( num_hidden,\n",
        "                                        num_classes,\n",
        "                                        cfg.REG_WEIGHT,\n",
        "                                        softmax_bound=cfg.SOFTMAX_BOUND,\n",
        "                                        # return_empirical=cfg.RETURN_EMPIRICAL,\n",
        "                                        # softmax_bound_empirical=cfg.SOFTMAX_BOUND_EMPIRICAL,\n",
        "                                        parameterization = cfg.PARAM,\n",
        "                                        return_ood=cfg.RETURN_OOD,\n",
        "                                        prior_scale=cfg.PRIOR_SCALE,\n",
        "                                       )\n",
        "\n",
        "    def _make_gen_vbll_layer(self, num_hidden, num_classes, cfg):\n",
        "        \"\"\" VBLL Generative classification head. \"\"\"\n",
        "        return vbll.GenClassification(  num_hidden,\n",
        "                                        num_classes,\n",
        "                                        cfg.REG_WEIGHT,\n",
        "                                        softmax_bound=cfg.SOFTMAX_BOUND,\n",
        "                                        # return_empirical=cfg.RETURN_EMPIRICAL,\n",
        "                                        # softmax_bound_empirical=cfg.SOFTMAX_BOUND_EMPIRICAL,\n",
        "                                        parameterization = cfg.PARAM,\n",
        "                                        return_ood=cfg.RETURN_OOD,\n",
        "                                        prior_scale=cfg.PRIOR_SCALE)\n",
        "\n",
        "    def train_loss(self, X_batch, y_batch, data_size=None, verbose=False):\n",
        "        data_size = data_size or X_batch.shape[0]\n",
        "        X_processed = self.process(X_batch)\n",
        "\n",
        "        loss = 0.\n",
        "        for i, (head, y) in enumerate(zip(self.heads, y_batch.T)):\n",
        "            loss1 = head(X_processed).train_loss_fn(y.long())\n",
        "            loss += loss1\n",
        "            if verbose:\n",
        "                print(f\"head={i} loss={loss1:.2f}\")\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict probabilities for each output given input data.\n",
        "\n",
        "        Parameters:\n",
        "        ----------\n",
        "        X : torch.Tensor\n",
        "            Input data. Shape (n_samples, input_dim).\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "        preds : torch.Tensor\n",
        "            Predicted probabilities for each output. Shape (n_samples, K).\n",
        "        \"\"\"\n",
        "        X_processed = self.process(X)\n",
        "\n",
        "        preds = []\n",
        "        for head in self.heads:\n",
        "            pred = head(X_processed).predictive.probs[:, 1]\n",
        "            preds.append(pred.unsqueeze(1))\n",
        "\n",
        "        preds = torch.cat(preds, dim=1)  # Shape: (n_samples, K)\n",
        "        return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IruZp097hq5s"
      },
      "source": [
        "## Synthetic Data from Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdWVTwniKJSd"
      },
      "outputs": [],
      "source": [
        "# Step 1: Generate synthetic data for multi-label classification\n",
        "# Assume N samples, D input features, and K labels\n",
        "N = 1000  # number of samples\n",
        "D = 10    # input features\n",
        "K = 4     # number of labels (multi-label classification)\n",
        "\n",
        "bias_on = 1.\n",
        "noise = 0.25\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Generate random data\n",
        "X = torch.randn(N, D)\n",
        "\n",
        "# Generate random weights for true labels\n",
        "true_W = torch.randn(D, K)\n",
        "# true_W = torch.ones(D, K)\n",
        "true_b = torch.randn(K)\n",
        "\n",
        "# Compute logits\n",
        "logits = X @ true_W + true_b*bias_on + torch.randn(N, K)*noise\n",
        "\n",
        "# Apply sigmoid to get probabilities\n",
        "probs = torch.sigmoid(logits)\n",
        "\n",
        "# Generate labels (multi-label)\n",
        "y = torch.bernoulli(probs)  # y is of shape (N, K), with 0s and 1s\n",
        "\n",
        "# Convert X,y to double precision (to match the expected dtype)\n",
        "X = X.double()\n",
        "y = y.double()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUS2ZZrWR1k0"
      },
      "outputs": [],
      "source": [
        "# Generate test data\n",
        "X_test = torch.randn(10000, D)\n",
        "\n",
        "# Compute logits\n",
        "logits = X_test @ true_W + true_b*bias_on + torch.randn(10000, K)*noise\n",
        "\n",
        "# Apply sigmoid to get probabilities\n",
        "probs = torch.sigmoid(logits)\n",
        "\n",
        "# Generate labels (multi-label)\n",
        "y_test = torch.bernoulli(probs)  # y is of shape (N, K), with 0s and 1s\n",
        "\n",
        "# Convert X,y to double precision (to match the expected dtype)\n",
        "X_test  = X_test.double()\n",
        "y_test = y_test.double()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY2h2Go3XgU5"
      },
      "source": [
        "## Synthethic Data: Shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pDUvrtOWrRu"
      },
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/matekrk/vi-per/refs/heads/main/generate_data_matchformat.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApWaAo6Quu9w"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from shapely.geometry import Point, Polygon\n",
        "\n",
        "from generate_data_matchformat import create_artificialshapes_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iardFlyBzed_",
        "outputId": "e01ac088-7d36-48e5-c147-8bed3a405e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your data path will be: size64_simplicity3_len1024_cbF_cfF_noF\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [01:01<00:00, 16.75it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGfCAYAAAAZGgYhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAchklEQVR4nO3df2xV9f3H8Vdr20sF7i2tcNuOltWIFkQYFih34L4ZdDbEGBjVocGMOSKRFRTQKE0muMVZovEXjh/qHLhMZLIEFRNgpGqdriBUiSizgjZrZ7kXXey9pbMXQj/fP4w3XsXJLbe8udfnIzkJPefc0/cnJOeZe3tvm+GccwIA4CzLtB4AAPDdRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmsvrrwmvWrNH999+vYDCocePG6dFHH9WkSZO+9XG9vb3q6OjQ4MGDlZGR0V/jAQD6iXNOXV1dKi4uVmbm/3ie4/rB5s2bXU5OjvvjH//o3n33XXfTTTe5vLw8FwqFvvWx7e3tThIbGxsbW4pv7e3t//N+n+Fc8n8ZaWVlpSZOnKjf//73kj5/VlNSUqLFixdr+fLl//Ox4XBYeXl5am9vl9frTfZoAIB+FolEVFJSos7OTvl8vm88L+kvwR0/flzNzc2qq6uL7cvMzFRVVZWampq+dn40GlU0Go193dXVJUnyer0ECABS2Lf9GCXpb0L45JNPdPLkSfn9/rj9fr9fwWDwa+fX19fL5/PFtpKSkmSPBAA4B5m/C66urk7hcDi2tbe3W48EADgLkv4S3AUXXKDzzjtPoVAobn8oFFJhYeHXzvd4PPJ4PMkeAwBwjkv6M6CcnBxVVFSooaEhtq+3t1cNDQ0KBALJ/nYAgBTVL58DWrZsmebNm6cJEyZo0qRJevjhh9Xd3a0bb7yxP74dACAF9UuA5syZo48//lgrVqxQMBjUD37wA+3YseNrb0wAAHx39cvngM5EJBKRz+dTOBzmbdgAkIJO9z5u/i44AMB3EwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwkXCAXn31VV199dUqLi5WRkaGnnvuubjjzjmtWLFCRUVFys3NVVVVlQ4dOpSseQEAaSLhAHV3d2vcuHFas2bNKY/fd999Wr16tdavX689e/Zo4MCBqq6uVk9PzxkPCwBIH1mJPmDGjBmaMWPGKY855/Twww/r17/+tWbOnClJ+tOf/iS/36/nnntO11133dceE41GFY1GY19HIpFERwIApKCk/gyotbVVwWBQVVVVsX0+n0+VlZVqamo65WPq6+vl8/liW0lJSTJHAgCco5IaoGAwKEny+/1x+/1+f+zYV9XV1SkcDse29vb2ZI4EADhHJfwSXLJ5PB55PB7rMQAAZ1lSnwEVFhZKkkKhUNz+UCgUOwYAgJTkAJWVlamwsFANDQ2xfZFIRHv27FEgEEjmtwIApLiEX4I7duyYDh8+HPu6tbVV+/fvV35+vkpLS7VkyRLdc889GjlypMrKynTXXXepuLhYs2bNSubcAIAUl3CA9u3bpx//+Mexr5ctWyZJmjdvnjZu3Kg77rhD3d3dWrBggTo7OzV16lTt2LFDAwYMSN7UAICUl+Gcc9ZDfFkkEpHP51M4HJbX67UeBwCQoNO9j/O74AAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwkFKD6+npNnDhRgwcP1rBhwzRr1iy1tLTEndPT06Pa2loVFBRo0KBBqqmpUSgUSurQAIDUl1CAGhsbVVtbq927d2vXrl06ceKErrzySnV3d8fOWbp0qbZt26YtW7aosbFRHR0dmj17dtIHBwCktgznnOvrgz/++GMNGzZMjY2N+tGPfqRwOKyhQ4dq06ZNuuaaayRJ7733nkaNGqWmpiZNnjz5W68ZiUTk8/kUDofl9Xr7OhoAwMjp3sfP6GdA4XBYkpSfny9Jam5u1okTJ1RVVRU7p7y8XKWlpWpqajrlNaLRqCKRSNwGAEh/fQ5Qb2+vlixZoilTpmjMmDGSpGAwqJycHOXl5cWd6/f7FQwGT3md+vp6+Xy+2FZSUtLXkQAAKaTPAaqtrdU777yjzZs3n9EAdXV1CofDsa29vf2MrgcASA1ZfXnQokWL9OKLL+rVV1/V8OHDY/sLCwt1/PhxdXZ2xj0LCoVCKiwsPOW1PB6PPB5PX8YAAKSwhJ4BOee0aNEibd26VS+99JLKysrijldUVCg7O1sNDQ2xfS0tLWpra1MgEEjOxACAtJDQM6Da2lpt2rRJzz//vAYPHhz7uY7P51Nubq58Pp/mz5+vZcuWKT8/X16vV4sXL1YgEDitd8ABAL47EnobdkZGxin3b9iwQb/4xS8kff5B1Ntuu03PPPOMotGoqqurtXbt2m98Ce6reBs2AKS2072Pn9HngPoDAQKA1HZWPgcEAEBfESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATCQVo3bp1Gjt2rLxer7xerwKBgLZv3x473tPTo9raWhUUFGjQoEGqqalRKBRK+tAAgNSXUICGDx+uVatWqbm5Wfv27dO0adM0c+ZMvfvuu5KkpUuXatu2bdqyZYsaGxvV0dGh2bNn98vgAIDUluGcc2dygfz8fN1///265pprNHToUG3atEnXXHONJOm9997TqFGj1NTUpMmTJ5/W9SKRiHw+n8LhsLxe75mMBgAwcLr38T7/DOjkyZPavHmzuru7FQgE1NzcrBMnTqiqqip2Tnl5uUpLS9XU1PSN14lGo4pEInEbACD9JRygAwcOaNCgQfJ4PLr55pu1detWjR49WsFgUDk5OcrLy4s73+/3KxgMfuP16uvr5fP5YltJSUnCiwAApJ6EA3TJJZdo//792rNnjxYuXKh58+bp4MGDfR6grq5O4XA4trW3t/f5WgCA1JGV6ANycnJ00UUXSZIqKiq0d+9ePfLII5ozZ46OHz+uzs7OuGdBoVBIhYWF33g9j8cjj8eT+OQAgJR2xp8D6u3tVTQaVUVFhbKzs9XQ0BA71tLSora2NgUCgTP9NgCANJPQM6C6ujrNmDFDpaWl6urq0qZNm/TKK69o586d8vl8mj9/vpYtW6b8/Hx5vV4tXrxYgUDgtN8BBwD47kgoQEePHtXPf/5zHTlyRD6fT2PHjtXOnTv1k5/8RJL00EMPKTMzUzU1NYpGo6qurtbatWv7ZXAAQGo7488BJRufAwKA1NbvnwMCAOBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATZxSgVatWKSMjQ0uWLInt6+npUW1trQoKCjRo0CDV1NQoFAqd6ZwAgDTT5wDt3btXjz32mMaOHRu3f+nSpdq2bZu2bNmixsZGdXR0aPbs2Wc8KAAgvfQpQMeOHdPcuXP1xBNPaMiQIbH94XBYTz75pB588EFNmzZNFRUV2rBhg/7xj39o9+7dSRsaAJD6+hSg2tpaXXXVVaqqqorb39zcrBMnTsTtLy8vV2lpqZqamk55rWg0qkgkErcBANJfVqIP2Lx5s958803t3bv3a8eCwaBycnKUl5cXt9/v9ysYDJ7yevX19frNb36T6BgAgBSX0DOg9vZ23XrrrXr66ac1YMCApAxQV1encDgc29rb25NyXQDAuS2hADU3N+vo0aO6/PLLlZWVpaysLDU2Nmr16tXKysqS3+/X8ePH1dnZGfe4UCikwsLCU17T4/HI6/XGbQCA9JfQS3DTp0/XgQMH4vbdeOONKi8v15133qmSkhJlZ2eroaFBNTU1kqSWlha1tbUpEAgkb2oAQMpLKECDBw/WmDFj4vYNHDhQBQUFsf3z58/XsmXLlJ+fL6/Xq8WLFysQCGjy5MnJmxoAkPISfhPCt3nooYeUmZmpmpoaRaNRVVdXa+3atcn+NgCAFJfhnHPWQ3xZJBKRz+dTOBzm50EAkIJO9z7O74IDAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYSCtDdd9+tjIyMuK28vDx2vKenR7W1tSooKNCgQYNUU1OjUCiU9KEBAKkv4WdAl156qY4cORLbXnvttdixpUuXatu2bdqyZYsaGxvV0dGh2bNnJ3VgAEB6yEr4AVlZKiws/Nr+cDisJ598Ups2bdK0adMkSRs2bNCoUaO0e/duTZ48+ZTXi0ajikajsa8jkUiiIwEAUlDCz4AOHTqk4uJiXXjhhZo7d67a2tokSc3NzTpx4oSqqqpi55aXl6u0tFRNTU3feL36+nr5fL7YVlJS0odlAABSTUIBqqys1MaNG7Vjxw6tW7dOra2tuuKKK9TV1aVgMKicnBzl5eXFPcbv9ysYDH7jNevq6hQOh2Nbe3t7nxYCAEgtCb0EN2PGjNi/x44dq8rKSo0YMULPPvuscnNz+zSAx+ORx+Pp02MBAKnrjN6GnZeXp4svvliHDx9WYWGhjh8/rs7OzrhzQqHQKX9mBAD4bjujAB07dkwffPCBioqKVFFRoezsbDU0NMSOt7S0qK2tTYFA4IwHBQCkl4Regrv99tt19dVXa8SIEero6NDKlSt13nnn6frrr5fP59P8+fO1bNky5efny+v1avHixQoEAt/4DjgAwHdXQgH697//reuvv17/+c9/NHToUE2dOlW7d+/W0KFDJUkPPfSQMjMzVVNTo2g0qurqaq1du7ZfBgcApLYM55yzHuLLIpGIfD6fwuGwvF6v9TgAgASd7n2c3wUHADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgIuEAffTRR7rhhhtUUFCg3NxcXXbZZdq3b1/suHNOK1asUFFRkXJzc1VVVaVDhw4ldWgAQOpLKECffvqppkyZouzsbG3fvl0HDx7UAw88oCFDhsTOue+++7R69WqtX79ee/bs0cCBA1VdXa2enp6kDw8ASF0Zzjl3uicvX75cr7/+uv7+97+f8rhzTsXFxbrtttt0++23S5LC4bD8fr82btyo66677lu/RyQSkc/nUzgcltfrPd3RAADniNO9jyf0DOiFF17QhAkTdO2112rYsGEaP368nnjiidjx1tZWBYNBVVVVxfb5fD5VVlaqqanplNeMRqOKRCJxGwAg/SUUoA8//FDr1q3TyJEjtXPnTi1cuFC33HKLnnrqKUlSMBiUJPn9/rjH+f3+2LGvqq+vl8/ni20lJSV9WQcAIMUkFKDe3l5dfvnluvfeezV+/HgtWLBAN910k9avX9/nAerq6hQOh2Nbe3t7n68FAEgdCQWoqKhIo0ePjts3atQotbW1SZIKCwslSaFQKO6cUCgUO/ZVHo9HXq83bgMApL+EAjRlyhS1tLTE7Xv//fc1YsQISVJZWZkKCwvV0NAQOx6JRLRnzx4FAoEkjAsASBdZiZy8dOlS/fCHP9S9996rn/3sZ3rjjTf0+OOP6/HHH5ckZWRkaMmSJbrnnns0cuRIlZWV6a677lJxcbFmzZrVH/MDAFJUQgGaOHGitm7dqrq6Ov32t79VWVmZHn74Yc2dOzd2zh133KHu7m4tWLBAnZ2dmjp1qnbs2KEBAwYkfXgAQOpK6HNAZwOfAwKA1NYvnwMCACBZCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATCf027LPhi9+NGolEjCcBAPTFF/fvb/td1+dcgLq6uiRJJSUlxpMAAM5EV1eXfD7fNx4/5/4cQ29vrzo6OjR48GB1dXWppKRE7e3taf2nGSKRCOtME9+FNUqsM90ke53OOXV1dam4uFiZmd/8k55z7hlQZmamhg8fLunzv7AqSV6vN63/87/AOtPHd2GNEutMN8lc5/965vMF3oQAADBBgAAAJs7pAHk8Hq1cuVIej8d6lH7FOtPHd2GNEutMN1brPOfehAAA+G44p58BAQDSFwECAJggQAAAEwQIAGCCAAEATJzTAVqzZo2+//3va8CAAaqsrNQbb7xhPdIZefXVV3X11VeruLhYGRkZeu655+KOO+e0YsUKFRUVKTc3V1VVVTp06JDNsH1UX1+viRMnavDgwRo2bJhmzZqllpaWuHN6enpUW1urgoICDRo0SDU1NQqFQkYT9826des0duzY2CfHA4GAtm/fHjueDmv8qlWrVikjI0NLliyJ7UuHdd59993KyMiI28rLy2PH02GNX/joo490ww03qKCgQLm5ubrsssu0b9++2PGzfQ86ZwP0l7/8RcuWLdPKlSv15ptvaty4caqurtbRo0etR+uz7u5ujRs3TmvWrDnl8fvuu0+rV6/W+vXrtWfPHg0cOFDV1dXq6ek5y5P2XWNjo2pra7V7927t2rVLJ06c0JVXXqnu7u7YOUuXLtW2bdu0ZcsWNTY2qqOjQ7NnzzacOnHDhw/XqlWr1NzcrH379mnatGmaOXOm3n33XUnpscYv27t3rx577DGNHTs2bn+6rPPSSy/VkSNHYttrr70WO5Yua/z00081ZcoUZWdna/v27Tp48KAeeOABDRkyJHbOWb8HuXPUpEmTXG1tbezrkydPuuLiYldfX284VfJIclu3bo193dvb6woLC939998f29fZ2ek8Ho975plnDCZMjqNHjzpJrrGx0Tn3+Zqys7Pdli1bYuf885//dJJcU1OT1ZhJMWTIEPeHP/wh7dbY1dXlRo4c6Xbt2uX+7//+z916663OufT5v1y5cqUbN27cKY+lyxqdc+7OO+90U6dO/cbjFvegc/IZ0PHjx9Xc3KyqqqrYvszMTFVVVampqclwsv7T2tqqYDAYt2afz6fKysqUXnM4HJYk5efnS5Kam5t14sSJuHWWl5ertLQ0Zdd58uRJbd68Wd3d3QoEAmm3xtraWl111VVx65HS6//y0KFDKi4u1oUXXqi5c+eqra1NUnqt8YUXXtCECRN07bXXatiwYRo/fryeeOKJ2HGLe9A5GaBPPvlEJ0+elN/vj9vv9/sVDAaNpupfX6wrndbc29urJUuWaMqUKRozZoykz9eZk5OjvLy8uHNTcZ0HDhzQoEGD5PF4dPPNN2vr1q0aPXp0Wq1x8+bNevPNN1VfX/+1Y+myzsrKSm3cuFE7duzQunXr1NraqiuuuEJdXV1ps0ZJ+vDDD7Vu3TqNHDlSO3fu1MKFC3XLLbfoqaeekmRzDzrn/hwD0kdtba3eeeeduNfT08kll1yi/fv3KxwO669//avmzZunxsZG67GSpr29Xbfeeqt27dqlAQMGWI/Tb2bMmBH799ixY1VZWakRI0bo2WefVW5uruFkydXb26sJEybo3nvvlSSNHz9e77zzjtavX6958+aZzHROPgO64IILdN55533tnSahUEiFhYVGU/WvL9aVLmtetGiRXnzxRb388suxv+8kfb7O48ePq7OzM+78VFxnTk6OLrroIlVUVKi+vl7jxo3TI488kjZrbG5u1tGjR3X55ZcrKytLWVlZamxs1OrVq5WVlSW/358W6/yqvLw8XXzxxTp8+HDa/F9KUlFRkUaPHh23b9SoUbGXGy3uQedkgHJyclRRUaGGhobYvt7eXjU0NCgQCBhO1n/KyspUWFgYt+ZIJKI9e/ak1Jqdc1q0aJG2bt2ql156SWVlZXHHKyoqlJ2dHbfOlpYWtbW1pdQ6T6W3t1fRaDRt1jh9+nQdOHBA+/fvj20TJkzQ3LlzY/9Oh3V+1bFjx/TBBx+oqKgobf4vJWnKlClf+0jE+++/rxEjRkgyugf1y1sbkmDz5s3O4/G4jRs3uoMHD7oFCxa4vLw8FwwGrUfrs66uLvfWW2+5t956y0lyDz74oHvrrbfcv/71L+ecc6tWrXJ5eXnu+eefd2+//babOXOmKysrc5999pnx5Kdv4cKFzufzuVdeecUdOXIktv33v/+NnXPzzTe70tJS99JLL7l9+/a5QCDgAoGA4dSJW758uWtsbHStra3u7bffdsuXL3cZGRnub3/7m3MuPdZ4Kl9+F5xz6bHO2267zb3yyiuutbXVvf76666qqspdcMEF7ujRo8659Fijc8698cYbLisry/3ud79zhw4dck8//bQ7//zz3Z///OfYOWf7HnTOBsg55x599FFXWlrqcnJy3KRJk9zu3butRzojL7/8spP0tW3evHnOuc/fBnnXXXc5v9/vPB6Pmz59umtpabEdOkGnWp8kt2HDhtg5n332mfvVr37lhgwZ4s4//3z305/+1B05csRu6D745S9/6UaMGOFycnLc0KFD3fTp02PxcS491ngqXw1QOqxzzpw5rqioyOXk5Ljvfe97bs6cOe7w4cOx4+mwxi9s27bNjRkzxnk8HldeXu4ef/zxuONn+x7E3wMCAJg4J38GBABIfwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz8P7LhJVex27OJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGfCAYAAAAZGgYhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAebklEQVR4nO3df3CU1d3+8SsxyRKBbEiE3aQkND6iARGKAcIW7A9ImzKOAyVadHBKLSOPNKAQHSWdCrZjDaOjKBaCWgt2Kk2lM6jYEepEjdWGCFFGkBpB0yY17KJ9zG5IzYaS8/3Dcb9d2VU22XCyy/s1c2bI5z5753MIc1+c3Xs3KcYYIwAAzrJU2w0AAM5NBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwIq0wTrxpk2bdN9998nr9WrKlCl6+OGHNWPGjC99XF9fnzo6OjRy5EilpKQMVnsAgEFijFFXV5fy8/OVmvoF+xwzCOrq6kxGRob5zW9+Y95++21z4403muzsbOPz+b70se3t7UYSg8FgMBJ8tLe3f+H1PsWY+H8YaWlpqaZPn65f/epXkj7d1RQUFGjlypVas2bNFz7W7/crOztb7e3tysrKindrAIBBFggEVFBQoM7OTjmdzqjz4v4UXG9vr5qbm1VdXR2qpaamqqysTI2NjafNDwaDCgaDoa+7urokSVlZWQQQACSwL3sZJe43IXz00Uc6deqUXC5XWN3lcsnr9Z42v6amRk6nMzQKCgri3RIAYAiyfhdcdXW1/H5/aLS3t9tuCQBwFsT9KbgLLrhA5513nnw+X1jd5/PJ7XafNt/hcMjhcMS7DQDAEBf3HVBGRoZKSkpUX18fqvX19am+vl4ejyfe3w4AkKAG5X1AVVVVWrJkiaZNm6YZM2bowQcfVHd3t2644YbB+HYAgAQ0KAG0aNEiffjhh1q7dq28Xq++9rWvaffu3afdmAAAOHcNyvuABiIQCMjpdMrv93MbNgAkoDO9jlu/Cw4AcG4igAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsCLmAHrllVd01VVXKT8/XykpKXr66afDjhtjtHbtWuXl5SkzM1NlZWU6cuRIvPoFACSJmAOou7tbU6ZM0aZNmyIev/fee7Vx40Zt2bJFTU1NGj58uMrLy9XT0zPgZgEAySMt1gfMmzdP8+bNi3jMGKMHH3xQP/vZzzR//nxJ0m9/+1u5XC49/fTTuvbaa097TDAYVDAYDH0dCARibQkAkIDi+hpQa2urvF6vysrKQjWn06nS0lI1NjZGfExNTY2cTmdoFBQUxLMlAMAQFdcA8nq9kiSXyxVWd7lcoWOfV11dLb/fHxrt7e3xbAkAMETF/BRcvDkcDjkcDtttAADOsrjugNxutyTJ5/OF1X0+X+gYAABSnAOoqKhIbrdb9fX1oVogEFBTU5M8Hk88vxUAIMHF/BTciRMndPTo0dDXra2tOnDggHJyclRYWKhVq1bp7rvv1vjx41VUVKQ777xT+fn5WrBgQTz7BgAkuJgDaP/+/fr2t78d+rqqqkqStGTJEm3btk233367uru7tWzZMnV2dmr27NnavXu3hg0bFr+uAQAJL8UYY2w38d8CgYCcTqf8fr+ysrJstwMAiNGZXsf5LDgAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVqTZbgBIBh9FqXdGqZsodWeU+piYugESAzsgAIAVBBAAwAoCCABgBQEEALCCAAIAWMFdcDjnnYpSPxCl/maEWluUubH+D68vSn1shNrUKHO/FqWeHmMvwGBjBwQAsIIAAgBYQQABAKwggAAAVhBAAAAruAsO54zOKPUno9SPR6mnRKjF639y0c7TEaH2QZS5jVHqi6PUc7+wI2DwsAMCAFhBAAEArCCAAABWEEAAACsIIACAFdwFh6R0IkLtiShzP45Sj3S321ASrb//i1LfFqW+NEItO9ZmgH5gBwQAsIIAAgBYQQABAKwggAAAVsQUQDU1NZo+fbpGjhypMWPGaMGCBWppaQmb09PTo8rKSuXm5mrEiBGqqKiQz+eLa9MAgMSXYowxZzr5e9/7nq699lpNnz5d//nPf/TTn/5Uhw4d0uHDhzV8+HBJ0vLly/WnP/1J27Ztk9Pp1IoVK5SamqrXXnvtjL5HIBCQ0+mU3+9XVlZW/1aFc94fItT+dta7SAzjI9SifW4ccCbO9DoeUwB93ocffqgxY8aooaFB3/jGN+T3+zV69Ght375dV199tSTpnXfe0YQJE9TY2KiZM2fGrXHgixBAZ44AQryd6XV8QK8B+f1+SVJOTo4kqbm5WSdPnlRZWVloTnFxsQoLC9XYGPkzeoPBoAKBQNgAACS/fgdQX1+fVq1apVmzZmnSpEmSJK/Xq4yMDGVnZ4fNdblc8nq9Ec9TU1Mjp9MZGgUFBf1tCQCQQPodQJWVlTp06JDq6uoG1EB1dbX8fn9otLe3D+h8AIDE0K+P4lmxYoWee+45vfLKKxo7dmyo7na71dvbq87OzrBdkM/nk9vtjnguh8Mhh8PRnzYA+aPUW6LUcbojEWofRpk7ejAbwTknph2QMUYrVqzQzp079eKLL6qoqCjseElJidLT01VfXx+qtbS0qK2tTR6PJz4dAwCSQkw7oMrKSm3fvl3PPPOMRo4cGXpdx+l0KjMzU06nU0uXLlVVVZVycnKUlZWllStXyuPxnNEdcACAc0dMAVRbWytJ+ta3vhVW37p1q370ox9JkjZs2KDU1FRVVFQoGAyqvLxcmzdvjkuzAIDkMaD3AQ0G3geEWER7DeihCLW+wWwkyVRGqfMaEM7EWXkfEAAA/cUvpENC2x+lzm5nYJqj1L93VrtAsmMHBACwggACAFhBAAEArCCAAABWEEAAACu4Cw4Jrc12A0mKv1ecDeyAAABWEEAAACsIIACAFQQQAMAKAggAYAV3wSGh9dpuIEkFbTeAcwI7IACAFQQQAMAKAggAYAUBBACwggACAFjBXXBIaBm2G0hS/L3ibGAHBACwggACAFhBAAEArCCAAABWcBMCEpo7Sv0fZ7WL5BPt7xWIJ3ZAAAArCCAAgBUEEADACgIIAGAFAQQAsIK74JDQSqLU90aopQxmIwmsL0It2t8rEE/sgAAAVhBAAAArCCAAgBUEEADACgIIAGAFd8EhoY2JUv+fCLX3B7ORBFYYoTb2rHeBcxE7IACAFQQQAMAKAggAYAUBBACwggACAFjBXXBISvMi1LZGmfvvwWxkCHFEqV95VrsA/j92QAAAKwggAIAVBBAAwAoCCABgRUw3IdTW1qq2tlZ///vfJUmXXnqp1q5dq3nzPn3Jt6enR7feeqvq6uoUDAZVXl6uzZs3y+Vyxb1x4IuMjlBbHGXu76PUT8Spl7Pt/Cj1H0Sp5w1WI8CXiGkHNHbsWK1fv17Nzc3av3+/5syZo/nz5+vtt9+WJK1evVq7du3Sjh071NDQoI6ODi1cuHBQGgcAJLYUY4wZyAlycnJ033336eqrr9bo0aO1fft2XX311ZKkd955RxMmTFBjY6Nmzpx5RucLBAJyOp3y+/3KysoaSGtAmA+i1M/1HdBXB6kPnLvO9Dre79eATp06pbq6OnV3d8vj8ai5uVknT55UWVlZaE5xcbEKCwvV2NgY9TzBYFCBQCBsAACSX8wBdPDgQY0YMUIOh0M33XSTdu7cqYkTJ8rr9SojI0PZ2dlh810ul7xeb9Tz1dTUyOl0hkZBQUHMiwAAJJ6YA+iSSy7RgQMH1NTUpOXLl2vJkiU6fPhwvxuorq6W3+8Pjfb29n6fCwCQOGL+KJ6MjAxddNFFkqSSkhLt27dPDz30kBYtWqTe3l51dnaG7YJ8Pp/cbnfU8zkcDjkc0T4kBIifr0Sp/2+U+utR6gci1KI9cZzyRQ1FEO0F2RERal+LMndGlLozxl6AwTbg9wH19fUpGAyqpKRE6enpqq+vDx1raWlRW1ubPB7PQL8NACDJxLQDqq6u1rx581RYWKiuri5t375dL7/8svbs2SOn06mlS5eqqqpKOTk5ysrK0sqVK+XxeM74DjgAwLkjpgA6fvy4fvjDH+rYsWNyOp2aPHmy9uzZo+985zuSpA0bNig1NVUVFRVhb0QFAODzBvw+oHjjfUA427qi1HkNCOifQX8fEAAAA8EvpMM5b2SU+two9W9HqL0bZW60T1Poi1KPtNORpOIINf73iETHv2EAgBUEEADACgIIAGAFAQQAsIIAAgBYwV1wQIwi/a8t0l1qAL4YOyAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVgwogNavX6+UlBStWrUqVOvp6VFlZaVyc3M1YsQIVVRUyOfzDbRPAECS6XcA7du3T4888ogmT54cVl+9erV27dqlHTt2qKGhQR0dHVq4cOGAGwUAJJd+BdCJEye0ePFiPfbYYxo1alSo7vf79fjjj+uBBx7QnDlzVFJSoq1bt+qvf/2r9u7dG7emAQCJr18BVFlZqSuvvFJlZWVh9ebmZp08eTKsXlxcrMLCQjU2NkY8VzAYVCAQCBsAgOSXFusD6urq9MYbb2jfvn2nHfN6vcrIyFB2dnZY3eVyyev1RjxfTU2Nfv7zn8faBgAgwcW0A2pvb9ctt9yiJ598UsOGDYtLA9XV1fL7/aHR3t4el/MCAIa2mAKoublZx48f1+WXX660tDSlpaWpoaFBGzduVFpamlwul3p7e9XZ2Rn2OJ/PJ7fbHfGcDodDWVlZYQMAkPxiegpu7ty5OnjwYFjthhtuUHFxse644w4VFBQoPT1d9fX1qqiokCS1tLSora1NHo8nfl0DABJeTAE0cuRITZo0Kaw2fPhw5ebmhupLly5VVVWVcnJylJWVpZUrV8rj8WjmzJnx6xoAkPBivgnhy2zYsEGpqamqqKhQMBhUeXm5Nm/eHO9vAwBIcCnGGGO7if8WCATkdDrl9/t5PQgAEtCZXsf5LDgAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVsQUQHfddZdSUlLCRnFxceh4T0+PKisrlZubqxEjRqiiokI+ny/uTQMAEl/MO6BLL71Ux44dC41XX301dGz16tXatWuXduzYoYaGBnV0dGjhwoVxbRgAkBzSYn5AWprcbvdpdb/fr8cff1zbt2/XnDlzJElbt27VhAkTtHfvXs2cOTPi+YLBoILBYOjrQCAQa0sAgAQU8w7oyJEjys/P14UXXqjFixerra1NktTc3KyTJ0+qrKwsNLe4uFiFhYVqbGyMer6amho5nc7QKCgo6McyAACJJqYAKi0t1bZt27R7927V1taqtbVVV1xxhbq6uuT1epWRkaHs7Oywx7hcLnm93qjnrK6ult/vD4329vZ+LQQAkFhiegpu3rx5oT9PnjxZpaWlGjdunJ566illZmb2qwGHwyGHw9GvxwIAEteAbsPOzs7WxRdfrKNHj8rtdqu3t1ednZ1hc3w+X8TXjAAA57YBBdCJEyf03nvvKS8vTyUlJUpPT1d9fX3oeEtLi9ra2uTxeAbcKAAgucT0FNxtt92mq666SuPGjVNHR4fWrVun8847T9ddd52cTqeWLl2qqqoq5eTkKCsrSytXrpTH44l6BxwA4NwVUwD985//1HXXXad//etfGj16tGbPnq29e/dq9OjRkqQNGzYoNTVVFRUVCgaDKi8v1+bNmwelcQBAYksxxhjbTfy3QCAgp9Mpv9+vrKws2+0AAGJ0ptdxPgsOAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArYg6gDz74QNdff71yc3OVmZmpyy67TPv37w8dN8Zo7dq1ysvLU2ZmpsrKynTkyJG4Ng0ASHwxBdDHH3+sWbNmKT09Xc8//7wOHz6s+++/X6NGjQrNuffee7Vx40Zt2bJFTU1NGj58uMrLy9XT0xP35gEAiSvFGGPOdPKaNWv02muv6S9/+UvE48YY5efn69Zbb9Vtt90mSfL7/XK5XNq2bZuuvfbaL/0egUBATqdTfr9fWVlZZ9oaAGCIONPreEw7oGeffVbTpk3TNddcozFjxmjq1Kl67LHHQsdbW1vl9XpVVlYWqjmdTpWWlqqxsTHiOYPBoAKBQNgAACS/mALo/fffV21trcaPH689e/Zo+fLluvnmm/XEE09IkrxeryTJ5XKFPc7lcoWOfV5NTY2cTmdoFBQU9GcdAIAEE1MA9fX16fLLL9c999yjqVOnatmyZbrxxhu1ZcuWfjdQXV0tv98fGu3t7f0+FwAgccQUQHl5eZo4cWJYbcKECWpra5Mkud1uSZLP5wub4/P5Qsc+z+FwKCsrK2wAAJJfTAE0a9YstbS0hNXeffddjRs3TpJUVFQkt9ut+vr60PFAIKCmpiZ5PJ44tAsASBZpsUxevXq1vv71r+uee+7RD37wA73++ut69NFH9eijj0qSUlJStGrVKt19990aP368ioqKdOeddyo/P18LFiwYjP4BAAkqpgCaPn26du7cqerqav3iF79QUVGRHnzwQS1evDg05/bbb1d3d7eWLVumzs5OzZ49W7t379awYcPi3jwAIHHF9D6gs4H3AQFAYhuU9wEBABAvBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALAipk/DPhs++2zUQCBguRMAQH98dv3+ss+6HnIB1NXVJUkqKCiw3AkAYCC6urrkdDqjHh9yv46hr69PHR0dGjlypLq6ulRQUKD29vak/tUMgUCAdSaJc2GNEutMNvFepzFGXV1dys/PV2pq9Fd6htwOKDU1VWPHjpX06W9YlaSsrKyk/uF/hnUmj3NhjRLrTDbxXOcX7Xw+w00IAAArCCAAgBVDOoAcDofWrVsnh8Nhu5VBxTqTx7mwRol1Jhtb6xxyNyEAAM4NQ3oHBABIXgQQAMAKAggAYAUBBACwggACAFgxpANo06ZN+upXv6phw4aptLRUr7/+uu2WBuSVV17RVVddpfz8fKWkpOjpp58OO26M0dq1a5WXl6fMzEyVlZXpyJEjdprtp5qaGk2fPl0jR47UmDFjtGDBArW0tITN6enpUWVlpXJzczVixAhVVFTI5/NZ6rh/amtrNXny5NA7xz0ej55//vnQ8WRY4+etX79eKSkpWrVqVaiWDOu86667lJKSEjaKi4tDx5NhjZ/54IMPdP311ys3N1eZmZm67LLLtH///tDxs30NGrIB9Ic//EFVVVVat26d3njjDU2ZMkXl5eU6fvy47db6rbu7W1OmTNGmTZsiHr/33nu1ceNGbdmyRU1NTRo+fLjKy8vV09Nzljvtv4aGBlVWVmrv3r164YUXdPLkSX33u99Vd3d3aM7q1au1a9cu7dixQw0NDero6NDChQstdh27sWPHav369Wpubtb+/fs1Z84czZ8/X2+//bak5Fjjf9u3b58eeeQRTZ48OayeLOu89NJLdezYsdB49dVXQ8eSZY0ff/yxZs2apfT0dD3//PM6fPiw7r//fo0aNSo056xfg8wQNWPGDFNZWRn6+tSpUyY/P9/U1NRY7Cp+JJmdO3eGvu7r6zNut9vcd999oVpnZ6dxOBzm97//vYUO4+P48eNGkmloaDDGfLqm9PR0s2PHjtCcv/3tb0aSaWxstNVmXIwaNcr8+te/Tro1dnV1mfHjx5sXXnjBfPOb3zS33HKLMSZ5fpbr1q0zU6ZMiXgsWdZojDF33HGHmT17dtTjNq5BQ3IH1Nvbq+bmZpWVlYVqqampKisrU2Njo8XOBk9ra6u8Xm/Ymp1Op0pLSxN6zX6/X5KUk5MjSWpubtbJkyfD1llcXKzCwsKEXeepU6dUV1en7u5ueTyepFtjZWWlrrzyyrD1SMn1szxy5Ijy8/N14YUXavHixWpra5OUXGt89tlnNW3aNF1zzTUaM2aMpk6dqsceeyx03MY1aEgG0EcffaRTp07J5XKF1V0ul7xer6WuBtdn60qmNff19WnVqlWaNWuWJk2aJOnTdWZkZCg7OztsbiKu8+DBgxoxYoQcDoduuukm7dy5UxMnTkyqNdbV1emNN95QTU3NaceSZZ2lpaXatm2bdu/erdraWrW2tuqKK65QV1dX0qxRkt5//33V1tZq/Pjx2rNnj5YvX66bb75ZTzzxhCQ716Ah9+sYkDwqKyt16NChsOfTk8kll1yiAwcOyO/3649//KOWLFmihoYG223FTXt7u2655Ra98MILGjZsmO12Bs28efNCf548ebJKS0s1btw4PfXUU8rMzLTYWXz19fVp2rRpuueeeyRJU6dO1aFDh7RlyxYtWbLESk9Dcgd0wQUX6LzzzjvtThOfzye3222pq8H12bqSZc0rVqzQc889p5deein0+52kT9fZ29urzs7OsPmJuM6MjAxddNFFKikpUU1NjaZMmaKHHnooadbY3Nys48eP6/LLL1daWprS0tLU0NCgjRs3Ki0tTS6XKynW+XnZ2dm6+OKLdfTo0aT5WUpSXl6eJk6cGFabMGFC6OlGG9egIRlAGRkZKikpUX19fajW19en+vp6eTwei50NnqKiIrnd7rA1BwIBNTU1JdSajTFasWKFdu7cqRdffFFFRUVhx0tKSpSenh62zpaWFrW1tSXUOiPp6+tTMBhMmjXOnTtXBw8e1IEDB0Jj2rRpWrx4cejPybDOzztx4oTee+895eXlJc3PUpJmzZp12lsi3n33XY0bN06SpWvQoNzaEAd1dXXG4XCYbdu2mcOHD5tly5aZ7Oxs4/V6bbfWb11dXebNN980b775ppFkHnjgAfPmm2+af/zjH8YYY9avX2+ys7PNM888Y9566y0zf/58U1RUZD755BPLnZ+55cuXG6fTaV5++WVz7Nix0Pj3v/8dmnPTTTeZwsJC8+KLL5r9+/cbj8djPB6Pxa5jt2bNGtPQ0GBaW1vNW2+9ZdasWWNSUlLMn//8Z2NMcqwxkv++C86Y5Fjnrbfeal5++WXT2tpqXnvtNVNWVmYuuOACc/z4cWNMcqzRGGNef/11k5aWZn75y1+aI0eOmCeffNKcf/755ne/+11oztm+Bg3ZADLGmIcfftgUFhaajIwMM2PGDLN3717bLQ3ISy+9ZCSdNpYsWWKM+fQ2yDvvvNO4XC7jcDjM3LlzTUtLi92mYxRpfZLM1q1bQ3M++eQT85Of/MSMGjXKnH/++eb73/++OXbsmL2m++HHP/6xGTdunMnIyDCjR482c+fODYWPMcmxxkg+H0DJsM5FixaZvLw8k5GRYb7yla+YRYsWmaNHj4aOJ8MaP7Nr1y4zadIk43A4THFxsXn00UfDjp/taxC/DwgAYMWQfA0IAJD8CCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADAiv8HRWJjVJi7ml8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Configure and create\n",
        "\n",
        "size =  64\n",
        "# N = 256\n",
        "N = 1024\n",
        "main_dir = f\"\"\n",
        "\n",
        "coloured_background = False\n",
        "coloured_figues = False\n",
        "no_overlap = False\n",
        "bias_classes = [0.5, 0.5, 0.0, 0.0, 0.0, 0.0] # None\n",
        "simplicity = 3\n",
        "\n",
        "def get_appendix(coloured_background, coloured_figues, no_overlap):\n",
        "    def get_bool_str(v):\n",
        "        return \"T\" if v else \"F\"\n",
        "    return f\"cb{get_bool_str(coloured_background)}_cf{get_bool_str(coloured_figues)}_no{get_bool_str(no_overlap)}\"\n",
        "\n",
        "path_to_save = os.path.join(main_dir, f\"size{size}_\" + f\"simplicity{simplicity}_\" + f\"len{N}_\" + get_appendix(coloured_background, coloured_figues, no_overlap))\n",
        "\n",
        "datasetdir = os.path.join(path_to_save, \"images\")\n",
        "datasettxt = os.path.join(path_to_save, \"data.txt\")\n",
        "labelstxt = os.path.join(path_to_save, \"label.txt\")\n",
        "print(f\"Your data path will be: {path_to_save}\")\n",
        "\n",
        "dataset, labels = create_artificialshapes_dataset(N, size, datasetdir, datasettxt, labelstxt, no_overlap, coloured_figues, coloured_background, bias_classes, simplicity)\n",
        "\n",
        "# for inspection\n",
        "# datasetnpy = os.path.join(path_to_save, \"data.npy\")\n",
        "# np.save(datasetnpy, dataset)\n",
        "# labelsnpy = os.path.join(path_to_save, \"label.npy\")\n",
        "# np.save(labelsnpy, labels)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    plt.imshow(dataset[i])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "Ano0lJQtWu22",
        "outputId": "5861ba49-fe0a-4af0-97b8-71dc6d771d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your data path will be: size64_simplicity3_len1024_cbF_cfF_noF\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 349/1024 [00:06<00:13, 50.04it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3c9e49dd4b13>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Your data path will be: {path_to_save}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_artificialshapes_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasetdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasettxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelstxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_overlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoloured_figues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoloured_background\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplicity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# for inspection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/generate_data_matchformat.py\u001b[0m in \u001b[0;36mcreate_artificialshapes_dataset\u001b[0;34m(N, img_size, datadir, datatxt, labeltxt, no_overlap, coloured_figues, coloured_background, bias_classes, simplicity)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'image_{image_id}.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;31m# presumably this is here because subclasses can return?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[func-returns-value]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Need this if 'transparent=True', to reset colors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1893\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADMAAAAzCAYAAAA6oTAqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAAGKAAABigEzlzBYAAABBElEQVR4nO3Yvy4EURTA4e9a3epF6JQkIp5Ap/HIIqFQiIhE7QGERqEhrmI6lomLuSeb8ysnkzPzzb+72VJrrZakld4n8JclJmqJiVpiopaYqCUmaomJWmKilpioJSZqiYlaYqKWmKglJmqrPQ/+iGs8YQ17WP/FvNLrj/MTnH/YVnGAY5SGmV0es0ucLdhecIXTxrmTYyoufH3liwH72jB7csw9Hkb2ecZdw+zJMS/G34diuIM/bXLMBuYj+8yw1TB7cswM+76/8rvGwYvq8jU7xLbPoIpNHDXO7bbOvOEWN4ZFc44dw11rXcm7Yf6jpfptlpioJSZqiYlaYqKWmKgtFeYd/+grFoh/8WIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 64x64 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Configure and create\n",
        "\n",
        "size =  64\n",
        "# N = 256\n",
        "N = 1024\n",
        "main_dir = f\"\"\n",
        "\n",
        "coloured_background = False\n",
        "coloured_figues = False\n",
        "no_overlap = False\n",
        "bias_classes = [0.5, 0.5, 0.0, 0.0, 0.0, 0.0] # None\n",
        "simplicity = 3\n",
        "\n",
        "def get_appendix(coloured_background, coloured_figues, no_overlap):\n",
        "    def get_bool_str(v):\n",
        "        return \"T\" if v else \"F\"\n",
        "    return f\"cb{get_bool_str(coloured_background)}_cf{get_bool_str(coloured_figues)}_no{get_bool_str(no_overlap)}\"\n",
        "\n",
        "path_to_save = os.path.join(main_dir, f\"size{size}_\" + f\"simplicity{simplicity}_\" + f\"len{N}_\" + get_appendix(coloured_background, coloured_figues, no_overlap))\n",
        "\n",
        "datasetdir = os.path.join(path_to_save, \"images\")\n",
        "datasettxt = os.path.join(path_to_save, \"data.txt\")\n",
        "labelstxt = os.path.join(path_to_save, \"label.txt\")\n",
        "print(f\"Your data path will be: {path_to_save}\")\n",
        "\n",
        "dataset, labels = create_artificialshapes_dataset(N, size, datasetdir, datasettxt, labelstxt, no_overlap, coloured_figues, coloured_background, bias_classes, simplicity)\n",
        "\n",
        "# for inspection\n",
        "# datasetnpy = os.path.join(path_to_save, \"data.npy\")\n",
        "# np.save(datasetnpy, dataset)\n",
        "# labelsnpy = os.path.join(path_to_save, \"label.npy\")\n",
        "# np.save(labelsnpy, labels)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    plt.imshow(dataset[i])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eB9qRX40XLfD"
      },
      "outputs": [],
      "source": [
        "# Convert labels to flat binary array\n",
        "\n",
        "shapes = ['disk', 'square', 'triangle', 'star', 'hexagon', 'pentagon']\n",
        "\n",
        "label_ids = []\n",
        "K = 0\n",
        "shape2ix = {shape: i for i, shape in enumerate(shapes)}\n",
        "for labels1 in labels:\n",
        "    labels1 = [shape2ix[l[0]] for l in labels1]\n",
        "    if labels1:\n",
        "        K = max(K, max(labels1)+1)\n",
        "    label_ids.append(labels1)\n",
        "\n",
        "def create_binary_matrix(indices, num_cols):\n",
        "    return np.array([[1 if j in row else 0 for j in range(num_cols)] for row in indices])\n",
        "\n",
        "y = create_binary_matrix(label_ids, K)\n",
        "\n",
        "\n",
        "############################################################\n",
        "# Flatten Xs\n",
        "\n",
        "# X = dataset.reshape([len(dataset), -1])\n",
        "# D = X.shape[-1]\n",
        "\n",
        "# D = X.shape[1:]\n",
        "X = dataset\n",
        "X = X * (1/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N81NLZm-Xv3p",
        "outputId": "1eb4c103-841c-4894-8fc6-8ce49ce78c4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1024, 64, 64, 3)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZUH92V7a8CL",
        "outputId": "892e6962-9d34-4df4-ce1b-02d5822ee1e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500,\n",
              " 2,\n",
              " torch.Size([500, 3, 64, 64]),\n",
              " torch.Size([500, 2]),\n",
              " torch.Size([524, 3, 64, 64]),\n",
              " torch.Size([524, 2]))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N = 500  # training data size\n",
        "\n",
        "X_test = torch.tensor(X[N:]).permute(0, 3, 1, 2).double()\n",
        "y_test = torch.tensor(y[N:]).double()\n",
        "X = torch.tensor(X[:N]).permute(0, 3, 1, 2).double()\n",
        "y = torch.tensor(y[:N]).double()\n",
        "\n",
        "\n",
        "N, K, X.shape, y.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEylRgbqGn7F"
      },
      "outputs": [],
      "source": [
        "# Prepare DataLoader\n",
        "batch_size = 1000\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4I7wq50i88a"
      },
      "source": [
        "# Backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UW0dqX193kH"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define a backbone network\n",
        "class Backbone(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Backbone, self).__init__()\n",
        "        self.fc = nn.Linear(input_dim, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = self.relu(self.fc(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8gfYLocL48U"
      },
      "outputs": [],
      "source": [
        "p = 10\n",
        "D = 3*64**2\n",
        "backbone = Backbone(D, p).double()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzGrYRLKdXit"
      },
      "outputs": [],
      "source": [
        "# # Step 2: Define a backbone network\n",
        "# class Backbone(nn.Module):\n",
        "#     def __init__(self, input_dim, output_dim):\n",
        "#         super(Backbone, self).__init__()\n",
        "#         self.fc = nn.Linear(input_dim, 1024)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.fc2 = nn.Linear(1024, 256)\n",
        "#         self.fc3 = nn.Linear(256, 128)\n",
        "#         self.fc4 = nn.Linear(128, 128)\n",
        "#         self.fc5 = nn.Linear(128, 128)\n",
        "#         self.fc6 = nn.Linear(128, output_dim)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.relu(self.fc(x))\n",
        "#         x = self.relu(self.fc2(x))\n",
        "#         x = self.relu(self.fc3(x))\n",
        "#         x = self.relu(self.fc4(x))\n",
        "#         x = self.relu(self.fc5(x))\n",
        "#         x = self.fc6(x)\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiAcixPXwLgf"
      },
      "outputs": [],
      "source": [
        "# # Define backbone that outputs features of dimension p\n",
        "\n",
        "# p = 10  # dimension of features output by backbone\n",
        "# backbone = Backbone(D, p).double()  # Ensure the backbone uses double precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_nik_A8ugOF"
      },
      "outputs": [],
      "source": [
        "# !wget -q https://raw.githubusercontent.com/matekrk/vi-per/refs/heads/main/src/backbone_cnn.py\n",
        "# !wget -q https://raw.githubusercontent.com/matekrk/vi-per/refs/heads/main/src/backbone_build.py\n",
        "# !wget -q https://raw.githubusercontent.com/matekrk/vi-per/refs/heads/main/src/backbone_simple.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NL6FtEr5rC-"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, in_channel, option_id):\n",
        "        super(LeNet, self).__init__() # super().__init__()\n",
        "        # 0: size 28, 1: size 32, 2: size 64\n",
        "        options = [[[5, 1, 2], [5, 1, 0]],\n",
        "                   [[3, 1, 0], [3, 1, 0]],\n",
        "                   [[5, 1, 2], [5, 1, 0]]] # kernel, stride, padding\n",
        "        self.option_id = option_id\n",
        "        option = options[option_id]\n",
        "        self.conv1 = nn.Conv2d(in_channel, 6, kernel_size=option[0][0], stride=option[0][1], padding=option[0][2])\n",
        "        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=option[1][0], stride=option[1][1], padding=option[1][2])\n",
        "        self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        final_size = self.compute_final_size(option_id, in_channel)\n",
        "        self.fc1 = nn.Linear(16 * final_size * final_size, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        # self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def compute_final_size(self, option_id, in_channel):\n",
        "        if in_channel == 3:\n",
        "            match option_id:\n",
        "                case 0:\n",
        "                    return 5\n",
        "                case 1:\n",
        "                    return 6\n",
        "                case 2:\n",
        "                    return 14\n",
        "        return\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.avgpool1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.avgpool2(out)\n",
        "        #print(out.shape)\n",
        "        # out = out.view(out.size(0), -1)\n",
        "        out = torch.flatten(out, start_dim=1)\n",
        "        #print(out.shape)\n",
        "        out = self.fc1(out)\n",
        "        out = torch.nn.functional.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        # out = self.fc3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWr5dOEb3Dwr"
      },
      "outputs": [],
      "source": [
        "p = 84\n",
        "backbone = LeNet(3, 2).to(torch.double)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psUBBmjVzTpH"
      },
      "outputs": [],
      "source": [
        "class ConvNetBigger(nn.Module):\n",
        "    def __init__(self, input_channels, input_size):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=5, stride=1, padding=1)\n",
        "        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=1)\n",
        "        self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=1)\n",
        "        self.avgpool3 = nn.AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
        "        self.final_size = 128 * 7 * 7\n",
        "        self.fc1 = nn.Linear(self.final_size, 120)\n",
        "        self.fc2 = nn.Linear(120, 60)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool1(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.avgpool2(nn.functional.relu(self.conv2(x)))\n",
        "        x = self.avgpool3(nn.functional.relu(self.conv3(x)))\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1k46vl_471N"
      },
      "outputs": [],
      "source": [
        "p = 60\n",
        "backbone = ConvNetBigger(3, 64).to(torch.double)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1UP4Dq04J0X"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_channels, input_size):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.avgpool3 = nn.AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
        "        self.final_size = 64 * 9 * 9\n",
        "        self.fc1 = nn.Linear(self.final_size, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool1(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.avgpool2(nn.functional.relu(self.conv2(x)))\n",
        "        x = self.avgpool3(nn.functional.relu(self.conv3(x)))\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u0Bsk9fzYDn"
      },
      "outputs": [],
      "source": [
        "p = 64\n",
        "backbone = ConvNet(3, 64).to(torch.double)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKi1aZUNSnp3",
        "outputId": "ca4847f9-d088-449f-fe2a-61b74ce1ed92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer: conv1.weight | Number of parameters: 1728\n",
            "Layer: conv1.bias | Number of parameters: 64\n",
            "Layer: conv2.weight | Number of parameters: 36864\n",
            "Layer: conv2.bias | Number of parameters: 64\n",
            "Layer: conv3.weight | Number of parameters: 36864\n",
            "Layer: conv3.bias | Number of parameters: 64\n",
            "Layer: fc1.weight | Number of parameters: 331776\n",
            "Layer: fc1.bias | Number of parameters: 64\n"
          ]
        }
      ],
      "source": [
        "for name, param in backbone.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"Layer: {name} | Number of parameters: {param.numel()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTVW1V7cXCkv",
        "outputId": "5f9ec3ba-b922-496b-ffc9-a418088ae140"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool3): AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
              "  (fc1): Linear(in_features=5184, out_features=64, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pET1elLMvp6n"
      },
      "outputs": [],
      "source": [
        "# from backbone_cnn import network_9layers\n",
        "\n",
        "# p = 10\n",
        "# backbone = network_9layers(p).double()\n",
        "\n",
        "# backbone(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8orSrMGmuTzg"
      },
      "source": [
        "# Configure & Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8oaTRKnKM47"
      },
      "outputs": [],
      "source": [
        "# # Turn off backbone\n",
        "# backbone = None\n",
        "# p = X.shape[-1]\n",
        "\n",
        "beta = 0.\n",
        "# beta = 0.  # Turn off KL divergence / regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_3V0k-M3pbX",
        "outputId": "e9781826-d728-4763-d063-87a353b938eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LLModel] beta=1.0 input_dim=64 output_dim=2 intercept=True\n"
          ]
        }
      ],
      "source": [
        "# # Step 3: Instantiate the LogisticVI model\n",
        "beta = 1.0\n",
        "model_logisticvi = LogisticVI(beta=beta,\n",
        "                   p=p,\n",
        "                   K=K,\n",
        "                   method=0, # method==0/1 (proposed bound, diagonal/full covariance)\n",
        "                   backbone=backbone,\n",
        "                   l_max=10.0,\n",
        "                   intercept=True,\n",
        "                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jreA1sc0KmW",
        "outputId": "4eb376ce-bfe7-4456-fc6a-dce7925edbeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LLModel] beta=0.0 input_dim=64 output_dim=3 intercept=True\n"
          ]
        }
      ],
      "source": [
        "beta = 0.\n",
        "model = LogisticPointwise(beta=beta,\n",
        "                            p=p,\n",
        "                            K=K,\n",
        "                            backbone=backbone,\n",
        "                            intercept=True,\n",
        "                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bytk8lI-PSKQ"
      },
      "outputs": [],
      "source": [
        "# # # Discriminative VBLL\n",
        "# # class cfg:\n",
        "# #     TYPE = \"disc\"\n",
        "# #     REG_WEIGHT = 1./N\n",
        "# #     # PARAM = 'diagonal'\n",
        "# #     PARAM = 'dense'\n",
        "# #     RETURN_OOD = False\n",
        "# #     PRIOR_SCALE = 1.\n",
        "# #     SOFTMAX_BOUND = \"jensen\"\n",
        "# #     # RETURN_EMPIRICAL = True\n",
        "# #     # SOFTMAX_BOUND_EMPIRICAL = \"montecarlo\"\n",
        "\n",
        "\n",
        "# ## Generative VBLL\n",
        "# class cfg:\n",
        "#     TYPE = \"gen\"\n",
        "#     REG_WEIGHT = 1./N\n",
        "#     PARAM = 'diagonal'\n",
        "#     # PARAM = 'dense'\n",
        "#     RETURN_OOD = False\n",
        "#     PRIOR_SCALE = 1.\n",
        "#     SOFTMAX_BOUND = \"jensen\"\n",
        "#     # RETURN_EMPIRICAL = True\n",
        "#     # SOFTMAX_BOUND_EMPIRICAL = \"montecarlo\"\n",
        "\n",
        "\n",
        "# model = VBLLVI(\n",
        "#             p=p,\n",
        "#             K=K,\n",
        "#             vbll_cfg=cfg,\n",
        "#             backbone=backbone,\n",
        "#             intercept=True,\n",
        "#             )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgXXsE0Wi_b7"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "couPzcWFR5A_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Step 5: Make predictions and evaluate the model\n",
        "def evaluate(model, X_test, y_test, prefix = \"\"):\n",
        "    # Get predictions\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    # Binarize predictions using a threshold (e.g., 0.5)\n",
        "    threshold = 0.5\n",
        "    y_pred = (preds >= threshold).double()\n",
        "    assert y_pred.shape == y_test.shape, f\"y_pred.shape={y_pred.shape} != y_test.shape={y_test.shape}\"\n",
        "\n",
        "    f1s = []\n",
        "\n",
        "    # Compute evaluation metrics (accuracy and F1-score) per label\n",
        "    for k in range(K):\n",
        "        acc = accuracy_score(y_test[:, k].flatten().int().numpy(), y_pred[:, k].int().flatten().numpy())\n",
        "        precision = precision_score(y_test[:, k].numpy(), y_pred[:, k].numpy())\n",
        "        recall = recall_score(y_test[:, k].numpy(), y_pred[:, k].numpy())\n",
        "        f1 = f1_score(y_test[:, k].numpy(), y_pred[:, k].numpy())\n",
        "        f1s.append(f1)\n",
        "        print(f\"{prefix} : Label {k}: Accuracy = {acc:.2f}, Precision = {precision:.2f}, Recall = {recall:.2f}, F1-score = {f1:.2f}\")\n",
        "\n",
        "    return f1s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIEnOwyi4gRl"
      },
      "outputs": [],
      "source": [
        "evaluate(model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqlHdE8j80-p",
        "outputId": "6e8cc8ff-5208-44e1-f2e4-e77e57de82cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool3): AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
              "  (fc1): Linear(in_features=5184, out_features=64, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.backbone.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQJGd60ea5lB"
      },
      "outputs": [],
      "source": [
        "# Prepare DataLoader\n",
        "batch_size = 1000\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbux8OB5RyK1"
      },
      "outputs": [],
      "source": [
        "# p = 10\n",
        "# D = 3*64**2\n",
        "# backbone = Backbone(D, p).double()\n",
        "# model = LogisticPointwise(beta=beta,\n",
        "#                             p=p,\n",
        "#                             K=K,\n",
        "#                             backbone=backbone,\n",
        "#                             intercept=True,\n",
        "#                             )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2rSov0YStE6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhveGwtZL4K3"
      },
      "outputs": [],
      "source": [
        "model_init = copy.deepcopy(model)\n",
        "# model = copy.deepcopy(model_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1ZLc9X-OXRd",
        "outputId": "7d5e7112-6472-42ee-edf1-9e838ac93f43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.62, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.33, F1-score = 0.49\n",
            "train : Label 2: Accuracy = 0.35, F1-score = 0.52\n",
            "test : Label 0: Accuracy = 0.67, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.35, F1-score = 0.52\n",
            "test : Label 2: Accuracy = 0.35, F1-score = 0.52\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.0, 0.515003489183531, 0.515003489183531]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(model, X, y, prefix=\"train\")\n",
        "evaluate(model, X_test, y_test, prefix=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-QUhLU6TUMX"
      },
      "outputs": [],
      "source": [
        "# Define optimizer\n",
        "# optimizer = optim.Adam(model.params, lr=0.001)\n",
        "optimizer = optim.Adam(model.params, lr=0.001) # , weight_decay=1e-7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7POGSF0E5mu"
      },
      "outputs": [],
      "source": [
        "f1_thres = 0.55\n",
        "model_best = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRiraPl4Q49R",
        "outputId": "ce5a8916-db74-4047-8923-d6a050409e0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool3): AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
              "  (fc1): Linear(in_features=5184, out_features=64, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.backbone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3uH3tSj6N18"
      },
      "source": [
        "New Archi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ER_Ow_H6Omx",
        "outputId": "8463484c-b78e-4a27-c9ff-0ed5e87cfa74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_bce_loss=0.84  mean_reg=0.58\n",
            "Epoch 0, Loss: 0.8364\n",
            "train : Label 0: Accuracy = 0.62, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.67, F1-score = 0.00\n",
            "train : Label 2: Accuracy = 0.65, F1-score = 0.00\n",
            "test : Label 0: Accuracy = 0.67, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.65, F1-score = 0.00\n",
            "test : Label 2: Accuracy = 0.65, F1-score = 0.00\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.4688, 0.2622, 0.3244],\n",
            "        [0.4578, 0.2657, 0.3341],\n",
            "        [0.4664, 0.2602, 0.3233],\n",
            "        [0.4664, 0.2602, 0.3233],\n",
            "        [0.4660, 0.2606, 0.3270]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.64  mean_reg=0.58\n",
            "Epoch 10, Loss: 0.6366\n",
            "train : Label 0: Accuracy = 0.62, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.67, F1-score = 0.00\n",
            "train : Label 2: Accuracy = 0.65, F1-score = 0.00\n",
            "test : Label 0: Accuracy = 0.67, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.65, F1-score = 0.00\n",
            "test : Label 2: Accuracy = 0.65, F1-score = 0.00\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.3848, 0.2734, 0.3104],\n",
            "        [0.4117, 0.3241, 0.3304],\n",
            "        [0.3814, 0.2661, 0.3060],\n",
            "        [0.3814, 0.2661, 0.3060],\n",
            "        [0.3912, 0.2772, 0.3118]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.57  mean_reg=0.58\n",
            "Epoch 20, Loss: 0.5705\n",
            "train : Label 0: Accuracy = 0.69, F1-score = 0.59\n",
            "train : Label 1: Accuracy = 0.74, F1-score = 0.65\n",
            "train : Label 2: Accuracy = 0.65, F1-score = 0.00\n",
            "test : Label 0: Accuracy = 0.72, F1-score = 0.58\n",
            "test : Label 1: Accuracy = 0.71, F1-score = 0.60\n",
            "test : Label 2: Accuracy = 0.65, F1-score = 0.00\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.2488, 0.2377, 0.3891],\n",
            "        [0.5897, 0.6947, 0.3805],\n",
            "        [0.2266, 0.1737, 0.3800],\n",
            "        [0.2266, 0.1737, 0.3800],\n",
            "        [0.3027, 0.2765, 0.3989]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.57  mean_reg=0.58\n",
            "Epoch 30, Loss: 0.5733\n",
            "train : Label 0: Accuracy = 0.70, F1-score = 0.60\n",
            "train : Label 1: Accuracy = 0.76, F1-score = 0.56\n",
            "train : Label 2: Accuracy = 0.67, F1-score = 0.14\n",
            "test : Label 0: Accuracy = 0.71, F1-score = 0.55\n",
            "test : Label 1: Accuracy = 0.73, F1-score = 0.52\n",
            "test : Label 2: Accuracy = 0.66, F1-score = 0.10\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.2972, 0.1706, 0.4716],\n",
            "        [0.5666, 0.5026, 0.4122],\n",
            "        [0.2856, 0.1554, 0.4614],\n",
            "        [0.2856, 0.1554, 0.4614],\n",
            "        [0.3265, 0.1848, 0.4789]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.55  mean_reg=0.58\n",
            "Epoch 40, Loss: 0.5511\n",
            "train : Label 0: Accuracy = 0.71, F1-score = 0.58\n",
            "train : Label 1: Accuracy = 0.77, F1-score = 0.63\n",
            "train : Label 2: Accuracy = 0.65, F1-score = 0.05\n",
            "test : Label 0: Accuracy = 0.71, F1-score = 0.52\n",
            "test : Label 1: Accuracy = 0.73, F1-score = 0.55\n",
            "test : Label 2: Accuracy = 0.65, F1-score = 0.08\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.1968, 0.1227, 0.4075],\n",
            "        [0.5371, 0.6360, 0.2667],\n",
            "        [0.1852, 0.1027, 0.3773],\n",
            "        [0.1852, 0.1027, 0.3773],\n",
            "        [0.2244, 0.1423, 0.4359]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.53  mean_reg=0.58\n",
            "Epoch 50, Loss: 0.5263\n",
            "train : Label 0: Accuracy = 0.72, F1-score = 0.61\n",
            "train : Label 1: Accuracy = 0.78, F1-score = 0.62\n",
            "train : Label 2: Accuracy = 0.67, F1-score = 0.35\n",
            "test : Label 0: Accuracy = 0.71, F1-score = 0.55\n",
            "test : Label 1: Accuracy = 0.72, F1-score = 0.51\n",
            "test : Label 2: Accuracy = 0.66, F1-score = 0.36\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.1678, 0.0771, 0.3910],\n",
            "        [0.4597, 0.6122, 0.2801],\n",
            "        [0.1482, 0.0493, 0.3235],\n",
            "        [0.1482, 0.0493, 0.3235],\n",
            "        [0.2045, 0.0922, 0.4575]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.52  mean_reg=0.58\n",
            "Epoch 60, Loss: 0.5244\n",
            "train : Label 0: Accuracy = 0.73, F1-score = 0.57\n",
            "train : Label 1: Accuracy = 0.73, F1-score = 0.30\n",
            "train : Label 2: Accuracy = 0.66, F1-score = 0.27\n",
            "test : Label 0: Accuracy = 0.72, F1-score = 0.48\n",
            "test : Label 1: Accuracy = 0.68, F1-score = 0.19\n",
            "test : Label 2: Accuracy = 0.62, F1-score = 0.22\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.0632, 0.0118, 0.1831],\n",
            "        [0.5073, 0.3312, 0.3186],\n",
            "        [0.0475, 0.0087, 0.1343],\n",
            "        [0.0475, 0.0087, 0.1343],\n",
            "        [0.0647, 0.0193, 0.2128]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.51  mean_reg=0.58\n",
            "Epoch 70, Loss: 0.5147\n",
            "train : Label 0: Accuracy = 0.74, F1-score = 0.64\n",
            "train : Label 1: Accuracy = 0.80, F1-score = 0.68\n",
            "train : Label 2: Accuracy = 0.73, F1-score = 0.52\n",
            "test : Label 0: Accuracy = 0.72, F1-score = 0.57\n",
            "test : Label 1: Accuracy = 0.72, F1-score = 0.53\n",
            "test : Label 2: Accuracy = 0.66, F1-score = 0.42\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.1793, 0.1307, 0.4141],\n",
            "        [0.5788, 0.7265, 0.3049],\n",
            "        [0.1396, 0.1017, 0.3429],\n",
            "        [0.1396, 0.1017, 0.3429],\n",
            "        [0.1813, 0.2032, 0.4553]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.49  mean_reg=0.58\n",
            "Epoch 80, Loss: 0.4886\n",
            "train : Label 0: Accuracy = 0.75, F1-score = 0.67\n",
            "train : Label 1: Accuracy = 0.80, F1-score = 0.66\n",
            "train : Label 2: Accuracy = 0.70, F1-score = 0.48\n",
            "test : Label 0: Accuracy = 0.71, F1-score = 0.56\n",
            "test : Label 1: Accuracy = 0.72, F1-score = 0.51\n",
            "test : Label 2: Accuracy = 0.66, F1-score = 0.42\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.1127, 0.0379, 0.3089],\n",
            "        [0.6095, 0.7155, 0.3048],\n",
            "        [0.0747, 0.0223, 0.2060],\n",
            "        [0.0747, 0.0223, 0.2060],\n",
            "        [0.1191, 0.0815, 0.3796]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.47  mean_reg=0.58\n",
            "Epoch 90, Loss: 0.4687\n",
            "train : Label 0: Accuracy = 0.76, F1-score = 0.69\n",
            "train : Label 1: Accuracy = 0.82, F1-score = 0.69\n",
            "train : Label 2: Accuracy = 0.72, F1-score = 0.58\n",
            "test : Label 0: Accuracy = 0.70, F1-score = 0.55\n",
            "test : Label 1: Accuracy = 0.72, F1-score = 0.52\n",
            "test : Label 2: Accuracy = 0.66, F1-score = 0.52\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.1220, 0.0677, 0.4287],\n",
            "        [0.5323, 0.7283, 0.3348],\n",
            "        [0.0731, 0.0271, 0.2312],\n",
            "        [0.0731, 0.0271, 0.2312],\n",
            "        [0.1249, 0.1593, 0.5094]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.45  mean_reg=0.58\n",
            "Epoch 100, Loss: 0.4487\n",
            "train : Label 0: Accuracy = 0.78, F1-score = 0.70\n",
            "train : Label 1: Accuracy = 0.82, F1-score = 0.72\n",
            "train : Label 2: Accuracy = 0.75, F1-score = 0.62\n",
            "test : Label 0: Accuracy = 0.69, F1-score = 0.53\n",
            "test : Label 1: Accuracy = 0.73, F1-score = 0.55\n",
            "test : Label 2: Accuracy = 0.67, F1-score = 0.53\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.1279, 0.0772, 0.5045],\n",
            "        [0.4416, 0.7347, 0.3311],\n",
            "        [0.0604, 0.0178, 0.2146],\n",
            "        [0.0604, 0.0178, 0.2146],\n",
            "        [0.1554, 0.1489, 0.5438]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.48  mean_reg=0.58\n",
            "Epoch 110, Loss: 0.4799\n",
            "train : Label 0: Accuracy = 0.77, F1-score = 0.70\n",
            "train : Label 1: Accuracy = 0.82, F1-score = 0.66\n",
            "train : Label 2: Accuracy = 0.74, F1-score = 0.56\n",
            "test : Label 0: Accuracy = 0.72, F1-score = 0.59\n",
            "test : Label 1: Accuracy = 0.73, F1-score = 0.51\n",
            "test : Label 2: Accuracy = 0.67, F1-score = 0.47\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.0956, 0.0125, 0.2442],\n",
            "        [0.5323, 0.6599, 0.4705],\n",
            "        [0.0395, 0.0050, 0.0940],\n",
            "        [0.0395, 0.0050, 0.0940],\n",
            "        [0.0981, 0.0783, 0.3565]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.42  mean_reg=0.58\n",
            "Epoch 120, Loss: 0.4249\n",
            "train : Label 0: Accuracy = 0.77, F1-score = 0.67\n",
            "train : Label 1: Accuracy = 0.84, F1-score = 0.74\n",
            "train : Label 2: Accuracy = 0.77, F1-score = 0.65\n",
            "test : Label 0: Accuracy = 0.69, F1-score = 0.52\n",
            "test : Label 1: Accuracy = 0.74, F1-score = 0.57\n",
            "test : Label 2: Accuracy = 0.67, F1-score = 0.53\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.1506, 0.0469, 0.6005],\n",
            "        [0.2736, 0.6633, 0.2846],\n",
            "        [0.0655, 0.0051, 0.2027],\n",
            "        [0.0655, 0.0051, 0.2027],\n",
            "        [0.2104, 0.1162, 0.6479]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.39  mean_reg=0.58\n",
            "Epoch 130, Loss: 0.3912\n",
            "train : Label 0: Accuracy = 0.82, F1-score = 0.76\n",
            "train : Label 1: Accuracy = 0.87, F1-score = 0.79\n",
            "train : Label 2: Accuracy = 0.78, F1-score = 0.67\n",
            "test : Label 0: Accuracy = 0.71, F1-score = 0.58\n",
            "test : Label 1: Accuracy = 0.72, F1-score = 0.52\n",
            "test : Label 2: Accuracy = 0.67, F1-score = 0.53\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.1173, 0.0411, 0.5456],\n",
            "        [0.4425, 0.6489, 0.4183],\n",
            "        [0.0395, 0.0054, 0.1262],\n",
            "        [0.0395, 0.0054, 0.1262],\n",
            "        [0.1572, 0.1886, 0.6038]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.36  mean_reg=0.58\n",
            "Epoch 140, Loss: 0.3616\n",
            "train : Label 0: Accuracy = 0.83, F1-score = 0.77\n",
            "train : Label 1: Accuracy = 0.87, F1-score = 0.80\n",
            "train : Label 2: Accuracy = 0.80, F1-score = 0.69\n",
            "test : Label 0: Accuracy = 0.71, F1-score = 0.56\n",
            "test : Label 1: Accuracy = 0.73, F1-score = 0.55\n",
            "test : Label 2: Accuracy = 0.69, F1-score = 0.55\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[0.1049, 0.0328, 0.6570],\n",
            "        [0.3548, 0.7621, 0.3524],\n",
            "        [0.0294, 0.0021, 0.1051],\n",
            "        [0.0294, 0.0021, 0.1051],\n",
            "        [0.1352, 0.1888, 0.6746]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.34  mean_reg=0.58\n",
            "Epoch 150, Loss: 0.3368\n",
            "train : Label 0: Accuracy = 0.85, F1-score = 0.78\n",
            "train : Label 1: Accuracy = 0.88, F1-score = 0.82\n",
            "train : Label 2: Accuracy = 0.80, F1-score = 0.67\n",
            "test : Label 0: Accuracy = 0.72, F1-score = 0.52\n",
            "test : Label 1: Accuracy = 0.72, F1-score = 0.57\n",
            "test : Label 2: Accuracy = 0.70, F1-score = 0.52\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[6.6834e-02, 1.6940e-02, 6.1503e-01],\n",
            "        [2.3590e-01, 7.5532e-01, 2.7399e-01],\n",
            "        [1.8198e-02, 6.0506e-04, 5.7375e-02],\n",
            "        [1.8198e-02, 6.0506e-04, 5.7375e-02],\n",
            "        [1.0843e-01, 2.2801e-01, 6.3574e-01]], dtype=torch.float64,\n",
            "       grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.31  mean_reg=0.58\n",
            "Epoch 160, Loss: 0.3129\n",
            "train : Label 0: Accuracy = 0.87, F1-score = 0.82\n",
            "train : Label 1: Accuracy = 0.89, F1-score = 0.84\n",
            "train : Label 2: Accuracy = 0.82, F1-score = 0.72\n",
            "test : Label 0: Accuracy = 0.70, F1-score = 0.54\n",
            "test : Label 1: Accuracy = 0.73, F1-score = 0.58\n",
            "test : Label 2: Accuracy = 0.70, F1-score = 0.54\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[7.7858e-02, 2.2647e-02, 7.1797e-01],\n",
            "        [1.9938e-01, 7.9594e-01, 2.7807e-01],\n",
            "        [1.8478e-02, 6.5736e-04, 6.8332e-02],\n",
            "        [1.8478e-02, 6.5736e-04, 6.8332e-02],\n",
            "        [1.3569e-01, 2.7249e-01, 6.8048e-01]], dtype=torch.float64,\n",
            "       grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.28  mean_reg=0.58\n",
            "Epoch 170, Loss: 0.2768\n",
            "train : Label 0: Accuracy = 0.90, F1-score = 0.86\n",
            "train : Label 1: Accuracy = 0.90, F1-score = 0.85\n",
            "train : Label 2: Accuracy = 0.84, F1-score = 0.77\n",
            "test : Label 0: Accuracy = 0.72, F1-score = 0.56\n",
            "test : Label 1: Accuracy = 0.73, F1-score = 0.58\n",
            "test : Label 2: Accuracy = 0.69, F1-score = 0.58\n",
            "true tensor([[0., 1., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 1.]], dtype=torch.float64) pred tensor([[5.4945e-02, 1.7420e-02, 7.6955e-01],\n",
            "        [2.4137e-01, 8.2397e-01, 3.4469e-01],\n",
            "        [1.1363e-02, 3.4066e-04, 4.9065e-02],\n",
            "        [1.1363e-02, 3.4066e-04, 4.9065e-02],\n",
            "        [1.2651e-01, 2.8814e-01, 7.1743e-01]], dtype=torch.float64,\n",
            "       grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train the model\n",
        "n_epochs = 300  # Set to a small value for this example\n",
        "\n",
        "data_size = X.shape[0]\n",
        "for epoch in range(n_epochs):\n",
        "    verbose = (epoch%10==0)\n",
        "\n",
        "    for X_batch, y_batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.train_loss(X_batch, y_batch, data_size, verbose=verbose)\n",
        "        loss.backward()\n",
        "        # for i in model.params:\n",
        "        #   print(i.grad)\n",
        "        optimizer.step()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "        evaluate(model, X, y, prefix=\"train\")\n",
        "        f1_test = evaluate(model, X_test, y_test, prefix=\"test\")\n",
        "        f1_test = sum(f1_test) / len(f1_test)\n",
        "        if f1_test > f1_thres:\n",
        "          f1_thres = f1_test\n",
        "          model_best = copy.deepcopy(model)\n",
        "        n_test_data_pred = 5\n",
        "        preds = model.predict(X_test[0:n_test_data_pred])\n",
        "        print(\"true\", y_test[0:n_test_data_pred], \"pred\", preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaE0_QczIh6E",
        "outputId": "0cace1a8-8079-4771-ce8a-b06156a499eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_bce_loss=0.28  mean_reg=0.40\n",
            "Epoch 200, Loss: 0.2841\n",
            "train : Label 0: Accuracy = 0.86, F1-score = 0.67\n",
            "train : Label 1: Accuracy = 0.87, F1-score = 0.71\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.44\n",
            "test : Label 1: Accuracy = 0.77, F1-score = 0.46\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.2630, 0.5407],\n",
            "        [0.0098, 0.0104],\n",
            "        [0.0098, 0.0104],\n",
            "        [0.0098, 0.0104],\n",
            "        [0.0098, 0.0104]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.27  mean_reg=0.40\n",
            "Epoch 210, Loss: 0.2709\n",
            "train : Label 0: Accuracy = 0.86, F1-score = 0.66\n",
            "train : Label 1: Accuracy = 0.88, F1-score = 0.76\n",
            "test : Label 0: Accuracy = 0.74, F1-score = 0.45\n",
            "test : Label 1: Accuracy = 0.77, F1-score = 0.53\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.1839, 0.5976],\n",
            "        [0.0131, 0.0123],\n",
            "        [0.0131, 0.0123],\n",
            "        [0.0131, 0.0123],\n",
            "        [0.0131, 0.0123]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.26  mean_reg=0.40\n",
            "Epoch 220, Loss: 0.2586\n",
            "train : Label 0: Accuracy = 0.87, F1-score = 0.70\n",
            "train : Label 1: Accuracy = 0.90, F1-score = 0.79\n",
            "test : Label 0: Accuracy = 0.74, F1-score = 0.46\n",
            "test : Label 1: Accuracy = 0.78, F1-score = 0.56\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.2251, 0.5910],\n",
            "        [0.0097, 0.0102],\n",
            "        [0.0097, 0.0102],\n",
            "        [0.0097, 0.0102],\n",
            "        [0.0097, 0.0102]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.26  mean_reg=0.40\n",
            "Epoch 230, Loss: 0.2597\n",
            "train : Label 0: Accuracy = 0.88, F1-score = 0.75\n",
            "train : Label 1: Accuracy = 0.90, F1-score = 0.81\n",
            "test : Label 0: Accuracy = 0.76, F1-score = 0.50\n",
            "test : Label 1: Accuracy = 0.76, F1-score = 0.55\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.2038, 0.6591],\n",
            "        [0.0292, 0.0252],\n",
            "        [0.0292, 0.0252],\n",
            "        [0.0292, 0.0252],\n",
            "        [0.0292, 0.0252]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.24  mean_reg=0.40\n",
            "Epoch 240, Loss: 0.2399\n",
            "train : Label 0: Accuracy = 0.89, F1-score = 0.74\n",
            "train : Label 1: Accuracy = 0.89, F1-score = 0.80\n",
            "test : Label 0: Accuracy = 0.74, F1-score = 0.48\n",
            "test : Label 1: Accuracy = 0.78, F1-score = 0.56\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.2324, 0.6726],\n",
            "        [0.0175, 0.0101],\n",
            "        [0.0175, 0.0101],\n",
            "        [0.0175, 0.0101],\n",
            "        [0.0175, 0.0101]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.23  mean_reg=0.40\n",
            "Epoch 250, Loss: 0.2275\n",
            "train : Label 0: Accuracy = 0.90, F1-score = 0.78\n",
            "train : Label 1: Accuracy = 0.91, F1-score = 0.82\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.50\n",
            "test : Label 1: Accuracy = 0.77, F1-score = 0.54\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.3316, 0.6418],\n",
            "        [0.0089, 0.0045],\n",
            "        [0.0089, 0.0045],\n",
            "        [0.0089, 0.0045],\n",
            "        [0.0089, 0.0045]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.22  mean_reg=0.40\n",
            "Epoch 260, Loss: 0.2245\n",
            "train : Label 0: Accuracy = 0.90, F1-score = 0.75\n",
            "train : Label 1: Accuracy = 0.91, F1-score = 0.82\n",
            "test : Label 0: Accuracy = 0.76, F1-score = 0.49\n",
            "test : Label 1: Accuracy = 0.77, F1-score = 0.54\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.2031, 0.6100],\n",
            "        [0.0042, 0.0031],\n",
            "        [0.0042, 0.0031],\n",
            "        [0.0042, 0.0031],\n",
            "        [0.0042, 0.0031]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.21  mean_reg=0.40\n",
            "Epoch 270, Loss: 0.2136\n",
            "train : Label 0: Accuracy = 0.90, F1-score = 0.79\n",
            "train : Label 1: Accuracy = 0.92, F1-score = 0.84\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.51\n",
            "test : Label 1: Accuracy = 0.77, F1-score = 0.58\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.3070, 0.7502],\n",
            "        [0.0115, 0.0048],\n",
            "        [0.0115, 0.0048],\n",
            "        [0.0115, 0.0048],\n",
            "        [0.0115, 0.0048]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.20  mean_reg=0.40\n",
            "Epoch 280, Loss: 0.2006\n",
            "train : Label 0: Accuracy = 0.91, F1-score = 0.80\n",
            "train : Label 1: Accuracy = 0.92, F1-score = 0.85\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.51\n",
            "test : Label 1: Accuracy = 0.78, F1-score = 0.59\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.3495, 0.8044],\n",
            "        [0.0090, 0.0030],\n",
            "        [0.0090, 0.0030],\n",
            "        [0.0090, 0.0030],\n",
            "        [0.0090, 0.0030]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.19  mean_reg=0.40\n",
            "Epoch 290, Loss: 0.1890\n",
            "train : Label 0: Accuracy = 0.92, F1-score = 0.83\n",
            "train : Label 1: Accuracy = 0.93, F1-score = 0.86\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.50\n",
            "test : Label 1: Accuracy = 0.80, F1-score = 0.60\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.2524, 0.7775],\n",
            "        [0.0033, 0.0010],\n",
            "        [0.0033, 0.0010],\n",
            "        [0.0033, 0.0010],\n",
            "        [0.0033, 0.0010]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.18  mean_reg=0.40\n",
            "Epoch 300, Loss: 0.1797\n",
            "train : Label 0: Accuracy = 0.92, F1-score = 0.85\n",
            "train : Label 1: Accuracy = 0.94, F1-score = 0.87\n",
            "test : Label 0: Accuracy = 0.76, F1-score = 0.55\n",
            "test : Label 1: Accuracy = 0.79, F1-score = 0.60\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.3652, 0.8332],\n",
            "        [0.0052, 0.0008],\n",
            "        [0.0052, 0.0008],\n",
            "        [0.0052, 0.0008],\n",
            "        [0.0052, 0.0008]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.17  mean_reg=0.40\n",
            "Epoch 310, Loss: 0.1699\n",
            "train : Label 0: Accuracy = 0.92, F1-score = 0.83\n",
            "train : Label 1: Accuracy = 0.93, F1-score = 0.87\n",
            "test : Label 0: Accuracy = 0.76, F1-score = 0.52\n",
            "test : Label 1: Accuracy = 0.79, F1-score = 0.61\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.2033, 0.8592],\n",
            "        [0.0043, 0.0009],\n",
            "        [0.0043, 0.0009],\n",
            "        [0.0043, 0.0009],\n",
            "        [0.0043, 0.0009]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.17  mean_reg=0.40\n",
            "Epoch 320, Loss: 0.1685\n",
            "train : Label 0: Accuracy = 0.90, F1-score = 0.77\n",
            "train : Label 1: Accuracy = 0.93, F1-score = 0.86\n",
            "test : Label 0: Accuracy = 0.77, F1-score = 0.49\n",
            "test : Label 1: Accuracy = 0.79, F1-score = 0.60\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.0993, 0.8596],\n",
            "        [0.0042, 0.0017],\n",
            "        [0.0042, 0.0017],\n",
            "        [0.0042, 0.0017],\n",
            "        [0.0042, 0.0017]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.16  mean_reg=0.40\n",
            "Epoch 330, Loss: 0.1552\n",
            "train : Label 0: Accuracy = 0.94, F1-score = 0.87\n",
            "train : Label 1: Accuracy = 0.95, F1-score = 0.90\n",
            "test : Label 0: Accuracy = 0.76, F1-score = 0.54\n",
            "test : Label 1: Accuracy = 0.81, F1-score = 0.62\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[3.8162e-01, 8.9210e-01],\n",
            "        [1.8256e-03, 3.3203e-04],\n",
            "        [1.8256e-03, 3.3203e-04],\n",
            "        [1.8256e-03, 3.3203e-04],\n",
            "        [1.8256e-03, 3.3203e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.15  mean_reg=0.40\n",
            "Epoch 340, Loss: 0.1531\n",
            "train : Label 0: Accuracy = 0.94, F1-score = 0.86\n",
            "train : Label 1: Accuracy = 0.95, F1-score = 0.91\n",
            "test : Label 0: Accuracy = 0.77, F1-score = 0.50\n",
            "test : Label 1: Accuracy = 0.80, F1-score = 0.63\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[1.1540e-01, 9.5763e-01],\n",
            "        [2.7855e-03, 4.5610e-04],\n",
            "        [2.7855e-03, 4.5610e-04],\n",
            "        [2.7855e-03, 4.5610e-04],\n",
            "        [2.7855e-03, 4.5610e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.14  mean_reg=0.40\n",
            "Epoch 350, Loss: 0.1386\n",
            "train : Label 0: Accuracy = 0.94, F1-score = 0.86\n",
            "train : Label 1: Accuracy = 0.95, F1-score = 0.90\n",
            "test : Label 0: Accuracy = 0.76, F1-score = 0.53\n",
            "test : Label 1: Accuracy = 0.81, F1-score = 0.62\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[2.1080e-01, 9.1535e-01],\n",
            "        [3.3275e-03, 4.4335e-04],\n",
            "        [3.3275e-03, 4.4335e-04],\n",
            "        [3.3275e-03, 4.4335e-04],\n",
            "        [3.3275e-03, 4.4335e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.13  mean_reg=0.40\n",
            "Epoch 360, Loss: 0.1279\n",
            "train : Label 0: Accuracy = 0.95, F1-score = 0.90\n",
            "train : Label 1: Accuracy = 0.96, F1-score = 0.92\n",
            "test : Label 0: Accuracy = 0.77, F1-score = 0.56\n",
            "test : Label 1: Accuracy = 0.81, F1-score = 0.63\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[2.3007e-01, 9.2815e-01],\n",
            "        [9.4765e-04, 5.5606e-05],\n",
            "        [9.4765e-04, 5.5606e-05],\n",
            "        [9.4765e-04, 5.5606e-05],\n",
            "        [9.4765e-04, 5.5606e-05]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=1.66  mean_reg=0.40\n",
            "Epoch 370, Loss: 1.6649\n",
            "train : Label 0: Accuracy = 0.75, F1-score = 0.53\n",
            "train : Label 1: Accuracy = 0.79, F1-score = 0.38\n",
            "test : Label 0: Accuracy = 0.71, F1-score = 0.50\n",
            "test : Label 1: Accuracy = 0.79, F1-score = 0.41\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[8.2311e-01, 1.0101e-03],\n",
            "        [3.7815e-06, 5.0073e-14],\n",
            "        [3.7815e-06, 5.0073e-14],\n",
            "        [3.7815e-06, 5.0073e-14],\n",
            "        [3.7815e-06, 5.0073e-14]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.50  mean_reg=0.40\n",
            "Epoch 380, Loss: 0.4967\n",
            "train : Label 0: Accuracy = 0.77, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.79, F1-score = 0.58\n",
            "test : Label 0: Accuracy = 0.73, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.78, F1-score = 0.57\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.3084, 0.5967],\n",
            "        [0.2662, 0.3122],\n",
            "        [0.2662, 0.3122],\n",
            "        [0.2662, 0.3122],\n",
            "        [0.2662, 0.3122]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.53  mean_reg=0.40\n",
            "Epoch 390, Loss: 0.5319\n",
            "train : Label 0: Accuracy = 0.77, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.77, F1-score = 0.19\n",
            "test : Label 0: Accuracy = 0.73, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.77, F1-score = 0.16\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.1540, 0.2695],\n",
            "        [0.1414, 0.1644],\n",
            "        [0.1414, 0.1644],\n",
            "        [0.1414, 0.1644],\n",
            "        [0.1414, 0.1644]], dtype=torch.float64, grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train the model\n",
        "n_epochs = 200  # Set to a small value for this example\n",
        "\n",
        "data_size = X.shape[0]\n",
        "for epoch in range(200, 200+n_epochs):\n",
        "    verbose = (epoch%10==0)\n",
        "\n",
        "    for X_batch, y_batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.train_loss(X_batch, y_batch, data_size, verbose=verbose)\n",
        "        loss.backward()\n",
        "        # for i in model.params:\n",
        "        #   print(i.grad)\n",
        "        optimizer.step()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "        evaluate(model, X, y, prefix=\"train\")\n",
        "        f1_test = evaluate(model, X_test, y_test, prefix=\"test\")\n",
        "        f1_test = sum(f1_test) / len(f1_test)\n",
        "        if f1_test > f1_thres:\n",
        "          f1_thres = f1_test\n",
        "          model_best = copy.deepcopy(model)\n",
        "        n_test_data_pred = 5\n",
        "        preds = model.predict(X_test[0:n_test_data_pred])\n",
        "        print(\"true\", y_test[0:n_test_data_pred], \"pred\", preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTHyX4hed2Cl",
        "outputId": "5fa434fd-25b9-4117-895e-92dc5a290713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.77, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.81, F1-score = 0.58\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.0, 0.5752212389380531]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(model, X, y, prefix=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "345goaXJZZ3G",
        "outputId": "67e26760-8f9f-4e0f-9e6d-e9c3083de652"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'torch' has no attribute 'sa'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-1274171d76bc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module '{__name__}' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'sa'"
          ]
        }
      ],
      "source": [
        "torch.save(model.backbone.state_dict(), \"./backbone_circlessquares.pt\")\n",
        "for i, m in enumerate(model.m_list):\n",
        "  torch.save(m, f\"./att_{i}.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjzlRDUxySdi"
      },
      "source": [
        "With wd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pGcVZTAra8FY",
        "outputId": "66a75d83-e355-48a4-807a-e4a94a796a65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_bce_loss=0.60  mean_reg=0.38\n",
            "Epoch 0, Loss: 0.6033\n",
            "train : Label 0: Accuracy = 0.77, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.74, F1-score = 0.00\n",
            "test : Label 0: Accuracy = 0.73, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.76, F1-score = 0.00\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.1837, 0.2262],\n",
            "        [0.1821, 0.2227],\n",
            "        [0.1821, 0.2227],\n",
            "        [0.1821, 0.2227],\n",
            "        [0.1821, 0.2227]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.54  mean_reg=0.38\n",
            "Epoch 10, Loss: 0.5353\n",
            "train : Label 0: Accuracy = 0.77, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.74, F1-score = 0.00\n",
            "test : Label 0: Accuracy = 0.73, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.76, F1-score = 0.00\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.2120, 0.2348],\n",
            "        [0.1839, 0.1894],\n",
            "        [0.1839, 0.1894],\n",
            "        [0.1839, 0.1894],\n",
            "        [0.1839, 0.1894]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.50  mean_reg=0.38\n",
            "Epoch 20, Loss: 0.4980\n",
            "train : Label 0: Accuracy = 0.77, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.79, F1-score = 0.41\n",
            "test : Label 0: Accuracy = 0.73, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.79, F1-score = 0.40\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.2804, 0.3476],\n",
            "        [0.1792, 0.1478],\n",
            "        [0.1792, 0.1478],\n",
            "        [0.1792, 0.1478],\n",
            "        [0.1792, 0.1478]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.44  mean_reg=0.38\n",
            "Epoch 30, Loss: 0.4426\n",
            "train : Label 0: Accuracy = 0.79, F1-score = 0.33\n",
            "train : Label 1: Accuracy = 0.79, F1-score = 0.60\n",
            "test : Label 0: Accuracy = 0.73, F1-score = 0.25\n",
            "test : Label 1: Accuracy = 0.78, F1-score = 0.59\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.4633, 0.6221],\n",
            "        [0.1008, 0.0434],\n",
            "        [0.1008, 0.0434],\n",
            "        [0.1008, 0.0434],\n",
            "        [0.1008, 0.0434]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.47  mean_reg=0.38\n",
            "Epoch 40, Loss: 0.4709\n",
            "train : Label 0: Accuracy = 0.77, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.77, F1-score = 0.25\n",
            "test : Label 0: Accuracy = 0.73, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.78, F1-score = 0.27\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], dtype=torch.float64) pred tensor([[0.3034, 0.3741],\n",
            "        [0.1342, 0.1637],\n",
            "        [0.1342, 0.1637],\n",
            "        [0.1342, 0.1637],\n",
            "        [0.1342, 0.1637]], dtype=torch.float64, grad_fn=<CatBackward0>)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-df522dd754e1>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# for i in model.params:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fab742948768>\u001b[0m in \u001b[0;36mtrain_loss\u001b[0;34m(self, X_batch, y_batch, data_size, verbose)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mdata_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_size\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"preds.shape={preds.shape} != y_batch.shape={y_batch.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-fab742948768>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mShape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"\"\"\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mX_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-6d645ea7982f>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, X_batch)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mX_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mX_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-bc263ef7c10e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Step 4: Train the model\n",
        "n_epochs = 200  # Set to a small value for this example\n",
        "\n",
        "data_size = X.shape[0]\n",
        "for epoch in range(n_epochs):\n",
        "    verbose = (epoch%10==0)\n",
        "\n",
        "    for X_batch, y_batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.train_loss(X_batch, y_batch, data_size, verbose=verbose)\n",
        "        loss.backward()\n",
        "        # for i in model.params:\n",
        "        #   print(i.grad)\n",
        "        optimizer.step()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "        evaluate(model, X, y, prefix=\"train\")\n",
        "        f1_test = evaluate(model, X_test, y_test, prefix=\"test\")\n",
        "        f1_test = sum(f1_test) / len(f1_test)\n",
        "        if f1_test > f1_thres:\n",
        "          f1_thres = f1_test\n",
        "          model_best = copy.deepcopy(model)\n",
        "        n_test_data_pred = 5\n",
        "        preds = model.predict(X_test[0:n_test_data_pred])\n",
        "        print(\"true\", y_test[0:n_test_data_pred], \"pred\", preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5YIb52GyO_B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Njho0ZhVyOz4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnEOFDkWyPof"
      },
      "source": [
        "Without wd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URHEXJ3NRFeh",
        "outputId": "1fbfc95f-1b07-49bd-c33d-1a89035e376c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_bce_loss=0.70  mean_reg=0.38\n",
            "Epoch 0, Loss: 0.6991\n",
            "train : Label 0: Accuracy = 0.75, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.73, F1-score = 0.00\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.73, F1-score = 0.00\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]], dtype=torch.float64) pred tensor([[0.1916, 0.2827],\n",
            "        [0.1768, 0.2707],\n",
            "        [0.1858, 0.2783],\n",
            "        [0.1768, 0.2707],\n",
            "        [0.1776, 0.2711]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.56  mean_reg=0.38\n",
            "Epoch 10, Loss: 0.5632\n",
            "train : Label 0: Accuracy = 0.75, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.73, F1-score = 0.00\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.73, F1-score = 0.00\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]], dtype=torch.float64) pred tensor([[0.3183, 0.3413],\n",
            "        [0.2666, 0.2708],\n",
            "        [0.3018, 0.3193],\n",
            "        [0.2666, 0.2708],\n",
            "        [0.2699, 0.2751]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.52  mean_reg=0.38\n",
            "Epoch 20, Loss: 0.5201\n",
            "train : Label 0: Accuracy = 0.75, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.73, F1-score = 0.00\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.73, F1-score = 0.00\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]], dtype=torch.float64) pred tensor([[0.4049, 0.4499],\n",
            "        [0.1599, 0.1219],\n",
            "        [0.3271, 0.3574],\n",
            "        [0.1599, 0.1219],\n",
            "        [0.1738, 0.1386]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.50  mean_reg=0.38\n",
            "Epoch 30, Loss: 0.5017\n",
            "train : Label 0: Accuracy = 0.75, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.77, F1-score = 0.31\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.75, F1-score = 0.25\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]], dtype=torch.float64) pred tensor([[0.4757, 0.5856],\n",
            "        [0.1020, 0.0679],\n",
            "        [0.3750, 0.4582],\n",
            "        [0.1020, 0.0679],\n",
            "        [0.1184, 0.0824]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.47  mean_reg=0.38\n",
            "Epoch 40, Loss: 0.4709\n",
            "train : Label 0: Accuracy = 0.77, F1-score = 0.32\n",
            "train : Label 1: Accuracy = 0.76, F1-score = 0.50\n",
            "test : Label 0: Accuracy = 0.76, F1-score = 0.29\n",
            "test : Label 1: Accuracy = 0.77, F1-score = 0.51\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]], dtype=torch.float64) pred tensor([[0.4521, 0.6935],\n",
            "        [0.1976, 0.0940],\n",
            "        [0.4997, 0.6204],\n",
            "        [0.1976, 0.0940],\n",
            "        [0.2430, 0.1233]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.42  mean_reg=0.38\n",
            "Epoch 50, Loss: 0.4200\n",
            "train : Label 0: Accuracy = 0.77, F1-score = 0.39\n",
            "train : Label 1: Accuracy = 0.78, F1-score = 0.58\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.29\n",
            "test : Label 1: Accuracy = 0.76, F1-score = 0.51\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]], dtype=torch.float64) pred tensor([[0.1911, 0.7084],\n",
            "        [0.0847, 0.0804],\n",
            "        [0.3279, 0.6398],\n",
            "        [0.0847, 0.0804],\n",
            "        [0.1757, 0.1303]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.59  mean_reg=0.38\n",
            "Epoch 60, Loss: 0.5877\n",
            "train : Label 0: Accuracy = 0.79, F1-score = 0.57\n",
            "train : Label 1: Accuracy = 0.79, F1-score = 0.60\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.45\n",
            "test : Label 1: Accuracy = 0.75, F1-score = 0.51\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]], dtype=torch.float64) pred tensor([[0.1931, 0.6431],\n",
            "        [0.3920, 0.3249],\n",
            "        [0.3092, 0.6348],\n",
            "        [0.3920, 0.3249],\n",
            "        [0.4595, 0.3457]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.46  mean_reg=0.38\n",
            "Epoch 70, Loss: 0.4613\n",
            "train : Label 0: Accuracy = 0.77, F1-score = 0.35\n",
            "train : Label 1: Accuracy = 0.78, F1-score = 0.55\n",
            "test : Label 0: Accuracy = 0.76, F1-score = 0.28\n",
            "test : Label 1: Accuracy = 0.77, F1-score = 0.51\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]], dtype=torch.float64) pred tensor([[0.3172, 0.7438],\n",
            "        [0.1868, 0.1365],\n",
            "        [0.3696, 0.6717],\n",
            "        [0.1868, 0.1365],\n",
            "        [0.2386, 0.1621]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.39  mean_reg=0.38\n",
            "Epoch 80, Loss: 0.3896\n",
            "train : Label 0: Accuracy = 0.79, F1-score = 0.54\n",
            "train : Label 1: Accuracy = 0.79, F1-score = 0.46\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.45\n",
            "test : Label 1: Accuracy = 0.76, F1-score = 0.37\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]], dtype=torch.float64) pred tensor([[0.4928, 0.5029],\n",
            "        [0.0313, 0.0249],\n",
            "        [0.5330, 0.4553],\n",
            "        [0.0313, 0.0249],\n",
            "        [0.0615, 0.0357]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.45  mean_reg=0.38\n",
            "Epoch 90, Loss: 0.4515\n",
            "train : Label 0: Accuracy = 0.78, F1-score = 0.45\n",
            "train : Label 1: Accuracy = 0.79, F1-score = 0.47\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.38\n",
            "test : Label 1: Accuracy = 0.77, F1-score = 0.38\n",
            "true tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]], dtype=torch.float64) pred tensor([[0.6852, 0.4853],\n",
            "        [0.0112, 0.0263],\n",
            "        [0.5055, 0.5361],\n",
            "        [0.0112, 0.0263],\n",
            "        [0.0172, 0.0318]], dtype=torch.float64, grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train the model\n",
        "n_epochs = 100  # Set to a small value for this example\n",
        "\n",
        "data_size = X.shape[0]\n",
        "for epoch in range(n_epochs):\n",
        "    verbose = (epoch%10==0)\n",
        "\n",
        "    for X_batch, y_batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.train_loss(X_batch, y_batch, data_size, verbose=verbose)\n",
        "        loss.backward()\n",
        "        # for i in model.params:\n",
        "        #   print(i.grad)\n",
        "        optimizer.step()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "        evaluate(model, X, y, prefix=\"train\")\n",
        "        f1_test = evaluate(model, X_test, y_test, prefix=\"test\")\n",
        "        f1_test = sum(f1_test) / len(f1_test)\n",
        "        if f1_test > f1_thres:\n",
        "          f1_thres = f1_test\n",
        "          model_best = copy.deepcopy(model)\n",
        "        n_test_data_pred = 5\n",
        "        preds = model.predict(X_test[0:n_test_data_pred])\n",
        "        print(\"true\", y_test[0:n_test_data_pred], \"pred\", preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_YfYU95RFgq",
        "outputId": "311e3e46-cd3b-47da-c934-4f31bb660cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.86, F1-score = 0.66\n",
            "train : Label 1: Accuracy = 0.88, F1-score = 0.76\n",
            "test : Label 0: Accuracy = 0.75, F1-score = 0.43\n",
            "test : Label 1: Accuracy = 0.77, F1-score = 0.57\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.4291845493562232, 0.5693430656934306]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(model, X, y, prefix=\"train\")\n",
        "evaluate(model, X_test, y_test, prefix=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4elb33xHCTv",
        "outputId": "2a343a28-ce99-4211-a0cb-55964bf7e407"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.2228, 0.6997],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.1942, 0.5489],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.2821, 0.5432],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.0229, 0.0300],\n",
              "         [0.1917, 0.6382]], dtype=torch.float64, grad_fn=<CatBackward0>),\n",
              " tensor([[0., 1.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [1., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 1.]], dtype=torch.float64))"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(X_test[0:20]), y_test[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4v6orplt7rs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwsRGuL2FQiN"
      },
      "source": [
        "### Pointwise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92023qncFTEd",
        "outputId": "b7993270-1018-4b36-b277-76d6ab2fc2ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LLModel] beta=0.0 input_dim=64 output_dim=2 intercept=True\n",
            " : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            " : Label 1: Accuracy = 0.75, Precision = 0.45, Recall = 0.59, F1-score = 0.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.0, 0.5093632958801498]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = 64\n",
        "backbone = ConvNet(3, 64).to(torch.double)\n",
        "beta = 0.\n",
        "model = LogisticPointwise(beta=beta,\n",
        "                            p=p,\n",
        "                            K=K,\n",
        "                            backbone=backbone,\n",
        "                            intercept=True,\n",
        "                            )\n",
        "model.backbone.train()\n",
        "evaluate(model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DmfscsOFulW"
      },
      "outputs": [],
      "source": [
        "model_init = copy.deepcopy(model)\n",
        "f1_thres = 0.55\n",
        "model_best = None\n",
        "optimizer = optim.Adam(model.params, lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xNW5He_F2Mk",
        "outputId": "fd58ad9d-7a73-478a-be99-db63c0125598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_bce_loss=0.69  mean_reg=0.40\n",
            "Epoch 0, Loss: 0.6910\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.78, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.1775, 0.0239],\n",
            "        [0.1775, 0.0239],\n",
            "        [0.1773, 0.0245],\n",
            "        [0.1775, 0.0239],\n",
            "        [0.1814, 0.0257]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.57  mean_reg=0.40\n",
            "Epoch 10, Loss: 0.5739\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.78, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.2730, 0.3091],\n",
            "        [0.2730, 0.3091],\n",
            "        [0.2724, 0.3108],\n",
            "        [0.2730, 0.3091],\n",
            "        [0.2760, 0.3147]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.56  mean_reg=0.40\n",
            "Epoch 20, Loss: 0.5625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.78, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.2637, 0.2232],\n",
            "        [0.2637, 0.2232],\n",
            "        [0.2679, 0.2387],\n",
            "        [0.2637, 0.2232],\n",
            "        [0.2837, 0.2803]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.55  mean_reg=0.40\n",
            "Epoch 30, Loss: 0.5459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.78, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.1865, 0.1065],\n",
            "        [0.1865, 0.1065],\n",
            "        [0.2038, 0.1505],\n",
            "        [0.1865, 0.1065],\n",
            "        [0.2812, 0.3407]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.52  mean_reg=0.40\n",
            "Epoch 40, Loss: 0.5207\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.80, Precision = 0.76, Recall = 0.30, F1-score = 0.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.59, Recall = 0.17, F1-score = 0.26\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.1798, 0.0883],\n",
            "        [0.1798, 0.0883],\n",
            "        [0.2166, 0.1710],\n",
            "        [0.1798, 0.0883],\n",
            "        [0.3785, 0.6161]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.48  mean_reg=0.40\n",
            "Epoch 50, Loss: 0.4822\n",
            "train : Label 0: Accuracy = 0.75, Precision = 0.55, Recall = 0.30, F1-score = 0.38\n",
            "train : Label 1: Accuracy = 0.79, Precision = 0.65, Recall = 0.38, F1-score = 0.48\n",
            "test : Label 0: Accuracy = 0.72, Precision = 0.49, Recall = 0.22, F1-score = 0.31\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.53, Recall = 0.24, F1-score = 0.33\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.1147, 0.0417],\n",
            "        [0.1147, 0.0417],\n",
            "        [0.1983, 0.2104],\n",
            "        [0.1147, 0.0417],\n",
            "        [0.4154, 0.6934]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.46  mean_reg=0.40\n",
            "Epoch 60, Loss: 0.4561\n",
            "train : Label 0: Accuracy = 0.76, Precision = 0.59, Recall = 0.36, F1-score = 0.45\n",
            "train : Label 1: Accuracy = 0.79, Precision = 0.60, Recall = 0.50, F1-score = 0.54\n",
            "test : Label 0: Accuracy = 0.73, Precision = 0.55, Recall = 0.29, F1-score = 0.38\n",
            "test : Label 1: Accuracy = 0.80, Precision = 0.56, Recall = 0.46, F1-score = 0.50\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.1783, 0.1517],\n",
            "        [0.1783, 0.1517],\n",
            "        [0.2685, 0.4983],\n",
            "        [0.1783, 0.1517],\n",
            "        [0.4152, 0.7124]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.42  mean_reg=0.40\n",
            "Epoch 70, Loss: 0.4174\n",
            "train : Label 0: Accuracy = 0.76, Precision = 0.62, Recall = 0.25, F1-score = 0.36\n",
            "train : Label 1: Accuracy = 0.81, Precision = 0.67, Recall = 0.50, F1-score = 0.57\n",
            "test : Label 0: Accuracy = 0.73, Precision = 0.61, Recall = 0.16, F1-score = 0.25\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.60, Recall = 0.46, F1-score = 0.52\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.1241, 0.0453],\n",
            "        [0.1241, 0.0453],\n",
            "        [0.2889, 0.5273],\n",
            "        [0.1241, 0.0453],\n",
            "        [0.2867, 0.7558]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.52  mean_reg=0.40\n",
            "Epoch 80, Loss: 0.5219\n",
            "train : Label 0: Accuracy = 0.75, Precision = 0.53, Recall = 0.50, F1-score = 0.52\n",
            "train : Label 1: Accuracy = 0.82, Precision = 0.76, Recall = 0.41, F1-score = 0.53\n",
            "test : Label 0: Accuracy = 0.73, Precision = 0.51, Recall = 0.38, F1-score = 0.44\n",
            "test : Label 1: Accuracy = 0.80, Precision = 0.59, Recall = 0.32, F1-score = 0.42\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0750, 0.0821],\n",
            "        [0.0750, 0.0821],\n",
            "        [0.1531, 0.5546],\n",
            "        [0.0750, 0.0821],\n",
            "        [0.5057, 0.6583]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.44  mean_reg=0.40\n",
            "Epoch 90, Loss: 0.4359\n",
            "train : Label 0: Accuracy = 0.74, Precision = 1.00, Recall = 0.02, F1-score = 0.04\n",
            "train : Label 1: Accuracy = 0.82, Precision = 0.73, Recall = 0.45, F1-score = 0.56\n",
            "test : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.80, Precision = 0.58, Recall = 0.37, F1-score = 0.46\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0920, 0.0483],\n",
            "        [0.0920, 0.0483],\n",
            "        [0.2286, 0.6007],\n",
            "        [0.0920, 0.0483],\n",
            "        [0.2643, 0.6823]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.39  mean_reg=0.40\n",
            "Epoch 100, Loss: 0.3914\n",
            "train : Label 0: Accuracy = 0.78, Precision = 0.69, Recall = 0.31, F1-score = 0.43\n",
            "train : Label 1: Accuracy = 0.82, Precision = 0.71, Recall = 0.52, F1-score = 0.60\n",
            "test : Label 0: Accuracy = 0.75, Precision = 0.65, Recall = 0.22, F1-score = 0.33\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.53, Recall = 0.43, F1-score = 0.47\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0773, 0.0421],\n",
            "        [0.0773, 0.0421],\n",
            "        [0.3444, 0.7006],\n",
            "        [0.0773, 0.0421],\n",
            "        [0.3344, 0.7242]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.45  mean_reg=0.40\n",
            "Epoch 110, Loss: 0.4549\n",
            "train : Label 0: Accuracy = 0.80, Precision = 0.62, Recall = 0.58, F1-score = 0.60\n",
            "train : Label 1: Accuracy = 0.82, Precision = 0.83, Recall = 0.38, F1-score = 0.52\n",
            "test : Label 0: Accuracy = 0.75, Precision = 0.57, Recall = 0.40, F1-score = 0.47\n",
            "test : Label 1: Accuracy = 0.80, Precision = 0.60, Recall = 0.27, F1-score = 0.37\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0463, 0.0213],\n",
            "        [0.0463, 0.0213],\n",
            "        [0.3417, 0.7118],\n",
            "        [0.0463, 0.0213],\n",
            "        [0.4283, 0.6370]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.42  mean_reg=0.40\n",
            "Epoch 120, Loss: 0.4245\n",
            "train : Label 0: Accuracy = 0.78, Precision = 0.66, Recall = 0.37, F1-score = 0.48\n",
            "train : Label 1: Accuracy = 0.81, Precision = 0.68, Recall = 0.51, F1-score = 0.58\n",
            "test : Label 0: Accuracy = 0.74, Precision = 0.58, Recall = 0.29, F1-score = 0.38\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.54, Recall = 0.42, F1-score = 0.47\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.1545, 0.0525],\n",
            "        [0.1545, 0.0525],\n",
            "        [0.3378, 0.7260],\n",
            "        [0.1545, 0.0525],\n",
            "        [0.3127, 0.8093]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.41  mean_reg=0.40\n",
            "Epoch 130, Loss: 0.4140\n",
            "train : Label 0: Accuracy = 0.77, Precision = 0.58, Recall = 0.55, F1-score = 0.56\n",
            "train : Label 1: Accuracy = 0.81, Precision = 0.83, Recall = 0.31, F1-score = 0.45\n",
            "test : Label 0: Accuracy = 0.74, Precision = 0.54, Recall = 0.41, F1-score = 0.47\n",
            "test : Label 1: Accuracy = 0.80, Precision = 0.62, Recall = 0.27, F1-score = 0.38\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0344, 0.0124],\n",
            "        [0.0344, 0.0124],\n",
            "        [0.2791, 0.7554],\n",
            "        [0.0344, 0.0124],\n",
            "        [0.3590, 0.6101]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.36  mean_reg=0.40\n",
            "Epoch 140, Loss: 0.3612\n",
            "train : Label 0: Accuracy = 0.82, Precision = 0.65, Recall = 0.67, F1-score = 0.66\n",
            "train : Label 1: Accuracy = 0.84, Precision = 0.76, Recall = 0.54, F1-score = 0.63\n",
            "test : Label 0: Accuracy = 0.78, Precision = 0.61, Recall = 0.58, F1-score = 0.59\n",
            "test : Label 1: Accuracy = 0.80, Precision = 0.55, Recall = 0.41, F1-score = 0.47\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0592, 0.0366],\n",
            "        [0.0592, 0.0366],\n",
            "        [0.3458, 0.7722],\n",
            "        [0.0592, 0.0366],\n",
            "        [0.3231, 0.6791]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.35  mean_reg=0.40\n",
            "Epoch 150, Loss: 0.3485\n",
            "train : Label 0: Accuracy = 0.83, Precision = 0.72, Recall = 0.59, F1-score = 0.65\n",
            "train : Label 1: Accuracy = 0.84, Precision = 0.73, Recall = 0.62, F1-score = 0.67\n",
            "test : Label 0: Accuracy = 0.78, Precision = 0.63, Recall = 0.54, F1-score = 0.58\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.54, Recall = 0.43, F1-score = 0.48\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0512, 0.0192],\n",
            "        [0.0512, 0.0192],\n",
            "        [0.2747, 0.8337],\n",
            "        [0.0512, 0.0192],\n",
            "        [0.3281, 0.7689]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.31  mean_reg=0.40\n",
            "Epoch 160, Loss: 0.3137\n",
            "train : Label 0: Accuracy = 0.84, Precision = 0.73, Recall = 0.62, F1-score = 0.67\n",
            "train : Label 1: Accuracy = 0.85, Precision = 0.70, Recall = 0.73, F1-score = 0.71\n",
            "test : Label 0: Accuracy = 0.76, Precision = 0.60, Recall = 0.44, F1-score = 0.50\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.52, Recall = 0.57, F1-score = 0.54\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0236, 0.0289],\n",
            "        [0.0236, 0.0289],\n",
            "        [0.2585, 0.8124],\n",
            "        [0.0236, 0.0289],\n",
            "        [0.3702, 0.7248]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "mean_bce_loss=0.31  mean_reg=0.40\n",
            "Epoch 170, Loss: 0.3091\n",
            "train : Label 0: Accuracy = 0.83, Precision = 0.63, Recall = 0.88, F1-score = 0.73\n",
            "train : Label 1: Accuracy = 0.85, Precision = 0.80, Recall = 0.57, F1-score = 0.67\n",
            "test : Label 0: Accuracy = 0.79, Precision = 0.61, Recall = 0.70, F1-score = 0.65\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.59, Recall = 0.41, F1-score = 0.48\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0972, 0.0426],\n",
            "        [0.0972, 0.0426],\n",
            "        [0.2351, 0.8350],\n",
            "        [0.0972, 0.0426],\n",
            "        [0.5952, 0.3559]], dtype=torch.float64, grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train the model\n",
        "n_epochs = 500  # Set to a small value for this example\n",
        "\n",
        "data_size = X.shape[0]\n",
        "for epoch in range(n_epochs):\n",
        "    verbose = (epoch%10==0)\n",
        "\n",
        "    for X_batch, y_batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.train_loss(X_batch, y_batch, data_size, verbose=verbose)\n",
        "        loss.backward()\n",
        "        # for i in model.params:\n",
        "        #   print(i.grad)\n",
        "        optimizer.step()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "        evaluate(model, X, y, prefix=\"train\")\n",
        "        f1_test = evaluate(model, X_test, y_test, prefix=\"test\")\n",
        "        f1_test = sum(f1_test) / len(f1_test)\n",
        "        if f1_test > f1_thres:\n",
        "          f1_thres = f1_test\n",
        "          model_best = copy.deepcopy(model)\n",
        "          torch.save(model_best.backbone.state_dict(), \"./point_backbone_circlessquares.pt\")\n",
        "          for i, m in enumerate(model_best.m_list):\n",
        "            torch.save(m, f\"./point_att_{i}.pt\")\n",
        "        n_test_data_pred = 5\n",
        "        preds = model.predict(X_test[0:n_test_data_pred])\n",
        "        print(\"true\", y_test[0:n_test_data_pred], \"pred\", preds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH9OVJCJ4bZ5"
      },
      "source": [
        "### LogisticVI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzUd0amy6WMi",
        "outputId": "3dd09ff0-db80-46b3-d0a4-f68f0787e83c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LLModel] beta=1.0 input_dim=64 output_dim=2 intercept=True\n"
          ]
        }
      ],
      "source": [
        "beta = 1.0\n",
        "model_logisticvi = LogisticVI(beta=beta,\n",
        "                   p=p,\n",
        "                   K=K,\n",
        "                   method=0, # method==0/1 (proposed bound, diagonal/full covariance)\n",
        "                   backbone=backbone,\n",
        "                   l_max=10.0,\n",
        "                   intercept=True,\n",
        "                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPeu8GoB68LW"
      },
      "outputs": [],
      "source": [
        "model_logisticvi_init = copy.deepcopy(model_logisticvi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk-jfTJW4a-4",
        "outputId": "73da52f6-01e0-4dd9-9a74-ccef40070ea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            " : Label 1: Accuracy = 0.78, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avgpool3): AvgPool2d(kernel_size=2, stride=2, padding=1)\n",
              "  (fc1): Linear(in_features=5184, out_features=64, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(model_logisticvi, X_test, y_test)\n",
        "model_logisticvi.backbone.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVLMLMdx4a7m"
      },
      "outputs": [],
      "source": [
        "# model_logisticvi = copy.deepcopy(model_logisticvi_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWpHrPCl6mMz",
        "outputId": "d8588976-7eae-4ae9-846c-3118638061eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.78, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.0, 0.0]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(model_logisticvi, X, y, prefix=\"train\")\n",
        "evaluate(model_logisticvi, X_test, y_test, prefix=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlugXmCT6o6C"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model_logisticvi.params, lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4edIaU67ENq"
      },
      "outputs": [],
      "source": [
        "f1_thres = 0.55\n",
        "model_best = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFsuTX_H7HnV",
        "outputId": "2e7cb2a6-43dd-4b18-c8c7-ac1cec798161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ELBO=-1.66 mean_log_lik=-1.35 mean_kl_div=0.31\n",
            "Epoch 0, Loss: 1.6606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.78, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0706, 0.0289],\n",
            "        [0.0706, 0.0289],\n",
            "        [0.0716, 0.0298],\n",
            "        [0.0706, 0.0289],\n",
            "        [0.0720, 0.0320]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-1.47 mean_log_lik=-1.17 mean_kl_div=0.30\n",
            "Epoch 10, Loss: 1.4695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.78, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.2293, 0.1841],\n",
            "        [0.2293, 0.1841],\n",
            "        [0.2320, 0.1910],\n",
            "        [0.2293, 0.1841],\n",
            "        [0.2406, 0.2142]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-1.42 mean_log_lik=-1.12 mean_kl_div=0.30\n",
            "Epoch 20, Loss: 1.4177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.78, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.2557, 0.2294],\n",
            "        [0.2557, 0.2294],\n",
            "        [0.2648, 0.2665],\n",
            "        [0.2557, 0.2294],\n",
            "        [0.3231, 0.3896]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-1.29 mean_log_lik=-0.99 mean_kl_div=0.30\n",
            "Epoch 30, Loss: 1.2860\n",
            "train : Label 0: Accuracy = 0.72, Precision = 0.43, Recall = 0.20, F1-score = 0.27\n",
            "train : Label 1: Accuracy = 0.76, Precision = 0.52, Recall = 0.69, F1-score = 0.59\n",
            "test : Label 0: Accuracy = 0.72, Precision = 0.49, Recall = 0.20, F1-score = 0.29\n",
            "test : Label 1: Accuracy = 0.76, Precision = 0.47, Recall = 0.67, F1-score = 0.55\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.2259, 0.2356],\n",
            "        [0.2259, 0.2356],\n",
            "        [0.2787, 0.4724],\n",
            "        [0.2259, 0.2356],\n",
            "        [0.4663, 0.7783]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-1.23 mean_log_lik=-0.94 mean_kl_div=0.29\n",
            "Epoch 40, Loss: 1.2292\n",
            "train : Label 0: Accuracy = 0.74, Precision = 0.52, Recall = 0.34, F1-score = 0.41\n",
            "train : Label 1: Accuracy = 0.78, Precision = 0.58, Recall = 0.55, F1-score = 0.57\n",
            "test : Label 0: Accuracy = 0.72, Precision = 0.51, Recall = 0.28, F1-score = 0.36\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.51, Recall = 0.50, F1-score = 0.51\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.1389, 0.0772],\n",
            "        [0.1389, 0.0772],\n",
            "        [0.2571, 0.4108],\n",
            "        [0.1389, 0.0772],\n",
            "        [0.4534, 0.7736]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-1.33 mean_log_lik=-1.04 mean_kl_div=0.29\n",
            "Epoch 50, Loss: 1.3325\n",
            "train : Label 0: Accuracy = 0.76, Precision = 0.56, Recall = 0.49, F1-score = 0.52\n",
            "train : Label 1: Accuracy = 0.82, Precision = 0.72, Recall = 0.48, F1-score = 0.57\n",
            "test : Label 0: Accuracy = 0.72, Precision = 0.50, Recall = 0.35, F1-score = 0.42\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.58, Recall = 0.40, F1-score = 0.47\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0962, 0.0614],\n",
            "        [0.0962, 0.0614],\n",
            "        [0.2809, 0.6093],\n",
            "        [0.0962, 0.0614],\n",
            "        [0.4450, 0.6268]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-1.20 mean_log_lik=-0.91 mean_kl_div=0.29\n",
            "Epoch 60, Loss: 1.1983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train : Label 0: Accuracy = 0.74, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "train : Label 1: Accuracy = 0.82, Precision = 0.68, Recall = 0.55, F1-score = 0.61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test : Label 0: Accuracy = 0.72, Precision = 0.00, Recall = 0.00, F1-score = 0.00\n",
            "test : Label 1: Accuracy = 0.80, Precision = 0.54, Recall = 0.48, F1-score = 0.51\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.1226, 0.1045],\n",
            "        [0.1226, 0.1045],\n",
            "        [0.2461, 0.6363],\n",
            "        [0.1226, 0.1045],\n",
            "        [0.3115, 0.7027]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-1.31 mean_log_lik=-1.03 mean_kl_div=0.28\n",
            "Epoch 70, Loss: 1.3135\n",
            "train : Label 0: Accuracy = 0.81, Precision = 0.69, Recall = 0.54, F1-score = 0.60\n",
            "train : Label 1: Accuracy = 0.82, Precision = 0.86, Recall = 0.34, F1-score = 0.48\n",
            "test : Label 0: Accuracy = 0.72, Precision = 0.51, Recall = 0.33, F1-score = 0.40\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.72, Recall = 0.23, F1-score = 0.34\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0331, 0.0060],\n",
            "        [0.0331, 0.0060],\n",
            "        [0.2300, 0.5977],\n",
            "        [0.0331, 0.0060],\n",
            "        [0.3874, 0.5284]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-1.10 mean_log_lik=-0.82 mean_kl_div=0.28\n",
            "Epoch 80, Loss: 1.0973\n",
            "train : Label 0: Accuracy = 0.81, Precision = 0.69, Recall = 0.50, F1-score = 0.58\n",
            "train : Label 1: Accuracy = 0.83, Precision = 0.71, Recall = 0.57, F1-score = 0.63\n",
            "test : Label 0: Accuracy = 0.76, Precision = 0.63, Recall = 0.39, F1-score = 0.48\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.58, Recall = 0.47, F1-score = 0.52\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0842, 0.0529],\n",
            "        [0.0842, 0.0529],\n",
            "        [0.2723, 0.7241],\n",
            "        [0.0842, 0.0529],\n",
            "        [0.3702, 0.6642]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-1.02 mean_log_lik=-0.74 mean_kl_div=0.28\n",
            "Epoch 90, Loss: 1.0165\n",
            "train : Label 0: Accuracy = 0.83, Precision = 0.71, Recall = 0.58, F1-score = 0.64\n",
            "train : Label 1: Accuracy = 0.84, Precision = 0.74, Recall = 0.56, F1-score = 0.64\n",
            "test : Label 0: Accuracy = 0.76, Precision = 0.61, Recall = 0.45, F1-score = 0.52\n",
            "test : Label 1: Accuracy = 0.80, Precision = 0.56, Recall = 0.43, F1-score = 0.49\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0716, 0.0271],\n",
            "        [0.0716, 0.0271],\n",
            "        [0.2668, 0.7339],\n",
            "        [0.0716, 0.0271],\n",
            "        [0.3748, 0.6975]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.94 mean_log_lik=-0.66 mean_kl_div=0.27\n",
            "Epoch 100, Loss: 0.9361\n",
            "train : Label 0: Accuracy = 0.83, Precision = 0.72, Recall = 0.60, F1-score = 0.66\n",
            "train : Label 1: Accuracy = 0.84, Precision = 0.71, Recall = 0.66, F1-score = 0.68\n",
            "test : Label 0: Accuracy = 0.78, Precision = 0.63, Recall = 0.50, F1-score = 0.56\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.53, Recall = 0.48, F1-score = 0.50\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0311, 0.0101],\n",
            "        [0.0311, 0.0101],\n",
            "        [0.2920, 0.7749],\n",
            "        [0.0311, 0.0101],\n",
            "        [0.3659, 0.7168]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.87 mean_log_lik=-0.60 mean_kl_div=0.27\n",
            "Epoch 110, Loss: 0.8667\n",
            "train : Label 0: Accuracy = 0.86, Precision = 0.73, Recall = 0.73, F1-score = 0.73\n",
            "train : Label 1: Accuracy = 0.87, Precision = 0.78, Recall = 0.66, F1-score = 0.72\n",
            "test : Label 0: Accuracy = 0.78, Precision = 0.62, Recall = 0.54, F1-score = 0.58\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.58, Recall = 0.46, F1-score = 0.51\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0131, 0.0023],\n",
            "        [0.0131, 0.0023],\n",
            "        [0.4072, 0.7628],\n",
            "        [0.0131, 0.0023],\n",
            "        [0.3866, 0.7114]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.81 mean_log_lik=-0.54 mean_kl_div=0.27\n",
            "Epoch 120, Loss: 0.8065\n",
            "train : Label 0: Accuracy = 0.88, Precision = 0.77, Recall = 0.75, F1-score = 0.76\n",
            "train : Label 1: Accuracy = 0.87, Precision = 0.75, Recall = 0.74, F1-score = 0.75\n",
            "test : Label 0: Accuracy = 0.77, Precision = 0.61, Recall = 0.52, F1-score = 0.56\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.52, Recall = 0.50, F1-score = 0.51\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[0.0089, 0.0018],\n",
            "        [0.0089, 0.0018],\n",
            "        [0.3214, 0.7725],\n",
            "        [0.0089, 0.0018],\n",
            "        [0.3552, 0.8061]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.75 mean_log_lik=-0.49 mean_kl_div=0.26\n",
            "Epoch 130, Loss: 0.7500\n",
            "train : Label 0: Accuracy = 0.89, Precision = 0.79, Recall = 0.82, F1-score = 0.80\n",
            "train : Label 1: Accuracy = 0.89, Precision = 0.81, Recall = 0.76, F1-score = 0.78\n",
            "test : Label 0: Accuracy = 0.77, Precision = 0.61, Recall = 0.54, F1-score = 0.58\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.53, Recall = 0.48, F1-score = 0.50\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.9796e-03, 2.4505e-04],\n",
            "        [1.9796e-03, 2.4505e-04],\n",
            "        [3.1923e-01, 7.1547e-01],\n",
            "        [1.9796e-03, 2.4505e-04],\n",
            "        [4.6556e-01, 6.4215e-01]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.69 mean_log_lik=-0.43 mean_kl_div=0.26\n",
            "Epoch 140, Loss: 0.6905\n",
            "train : Label 0: Accuracy = 0.91, Precision = 0.82, Recall = 0.86, F1-score = 0.84\n",
            "train : Label 1: Accuracy = 0.92, Precision = 0.87, Recall = 0.81, F1-score = 0.84\n",
            "test : Label 0: Accuracy = 0.78, Precision = 0.62, Recall = 0.57, F1-score = 0.60\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.53, Recall = 0.52, F1-score = 0.52\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[8.6079e-04, 7.2301e-05],\n",
            "        [8.6079e-04, 7.2301e-05],\n",
            "        [2.5252e-01, 7.0967e-01],\n",
            "        [8.6079e-04, 7.2301e-05],\n",
            "        [5.3464e-01, 5.5194e-01]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.63 mean_log_lik=-0.37 mean_kl_div=0.26\n",
            "Epoch 150, Loss: 0.6313\n",
            "train : Label 0: Accuracy = 0.94, Precision = 0.86, Recall = 0.91, F1-score = 0.88\n",
            "train : Label 1: Accuracy = 0.94, Precision = 0.92, Recall = 0.83, F1-score = 0.87\n",
            "test : Label 0: Accuracy = 0.78, Precision = 0.63, Recall = 0.56, F1-score = 0.59\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.53, Recall = 0.50, F1-score = 0.52\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[2.7641e-04, 8.7757e-06],\n",
            "        [2.7641e-04, 8.7757e-06],\n",
            "        [2.1705e-01, 6.4041e-01],\n",
            "        [2.7641e-04, 8.7757e-06],\n",
            "        [6.4566e-01, 4.3320e-01]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.58 mean_log_lik=-0.32 mean_kl_div=0.26\n",
            "Epoch 160, Loss: 0.5781\n",
            "train : Label 0: Accuracy = 0.94, Precision = 0.87, Recall = 0.92, F1-score = 0.89\n",
            "train : Label 1: Accuracy = 0.95, Precision = 0.93, Recall = 0.88, F1-score = 0.90\n",
            "test : Label 0: Accuracy = 0.79, Precision = 0.64, Recall = 0.55, F1-score = 0.59\n",
            "test : Label 1: Accuracy = 0.78, Precision = 0.51, Recall = 0.55, F1-score = 0.53\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[7.7763e-05, 1.5841e-06],\n",
            "        [7.7763e-05, 1.5841e-06],\n",
            "        [1.3863e-01, 7.0503e-01],\n",
            "        [7.7763e-05, 1.5841e-06],\n",
            "        [6.9096e-01, 3.7738e-01]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.54 mean_log_lik=-0.28 mean_kl_div=0.25\n",
            "Epoch 170, Loss: 0.5353\n",
            "train : Label 0: Accuracy = 0.95, Precision = 0.88, Recall = 0.93, F1-score = 0.91\n",
            "train : Label 1: Accuracy = 0.96, Precision = 0.93, Recall = 0.90, F1-score = 0.92\n",
            "test : Label 0: Accuracy = 0.79, Precision = 0.64, Recall = 0.54, F1-score = 0.59\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.53, Recall = 0.55, F1-score = 0.54\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[2.4498e-05, 1.9331e-07],\n",
            "        [2.4498e-05, 1.9331e-07],\n",
            "        [1.2309e-01, 7.1729e-01],\n",
            "        [2.4498e-05, 1.9331e-07],\n",
            "        [7.5329e-01, 2.8563e-01]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.49 mean_log_lik=-0.23 mean_kl_div=0.25\n",
            "Epoch 180, Loss: 0.4854\n",
            "train : Label 0: Accuracy = 0.95, Precision = 0.90, Recall = 0.93, F1-score = 0.91\n",
            "train : Label 1: Accuracy = 0.97, Precision = 0.94, Recall = 0.95, F1-score = 0.95\n",
            "test : Label 0: Accuracy = 0.79, Precision = 0.66, Recall = 0.56, F1-score = 0.60\n",
            "test : Label 1: Accuracy = 0.79, Precision = 0.51, Recall = 0.57, F1-score = 0.54\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.3710e-05, 3.3114e-08],\n",
            "        [1.3710e-05, 3.3114e-08],\n",
            "        [8.6597e-02, 7.5750e-01],\n",
            "        [1.3710e-05, 3.3114e-08],\n",
            "        [8.9748e-01, 9.2733e-02]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.45 mean_log_lik=-0.20 mean_kl_div=0.25\n",
            "Epoch 190, Loss: 0.4463\n",
            "train : Label 0: Accuracy = 0.96, Precision = 0.89, Recall = 0.96, F1-score = 0.93\n",
            "train : Label 1: Accuracy = 0.98, Precision = 0.97, Recall = 0.95, F1-score = 0.96\n",
            "test : Label 0: Accuracy = 0.80, Precision = 0.65, Recall = 0.59, F1-score = 0.62\n",
            "test : Label 1: Accuracy = 0.80, Precision = 0.55, Recall = 0.57, F1-score = 0.56\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[6.0052e-06, 2.6124e-09],\n",
            "        [6.0052e-06, 2.6124e-09],\n",
            "        [4.9757e-02, 8.1059e-01],\n",
            "        [6.0052e-06, 2.6124e-09],\n",
            "        [9.2525e-01, 4.6122e-02]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.42 mean_log_lik=-0.17 mean_kl_div=0.25\n",
            "Epoch 200, Loss: 0.4159\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.96, F1-score = 0.94\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.97, Recall = 0.98, F1-score = 0.97\n",
            "test : Label 0: Accuracy = 0.79, Precision = 0.65, Recall = 0.56, F1-score = 0.60\n",
            "test : Label 1: Accuracy = 0.80, Precision = 0.54, Recall = 0.61, F1-score = 0.57\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[2.9050e-06, 3.2932e-10],\n",
            "        [2.9050e-06, 3.2932e-10],\n",
            "        [3.0119e-02, 8.5463e-01],\n",
            "        [2.9050e-06, 3.2932e-10],\n",
            "        [9.3940e-01, 2.7991e-02]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.39 mean_log_lik=-0.15 mean_kl_div=0.24\n",
            "Epoch 210, Loss: 0.3912\n",
            "train : Label 0: Accuracy = 0.96, Precision = 0.91, Recall = 0.95, F1-score = 0.93\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.97, Recall = 0.98, F1-score = 0.97\n",
            "test : Label 0: Accuracy = 0.79, Precision = 0.65, Recall = 0.58, F1-score = 0.61\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.56, Recall = 0.62, F1-score = 0.59\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[8.2091e-07, 2.5047e-11],\n",
            "        [8.2091e-07, 2.5047e-11],\n",
            "        [2.2088e-02, 8.8931e-01],\n",
            "        [8.2091e-07, 2.5047e-11],\n",
            "        [9.7055e-01, 1.4946e-02]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.37 mean_log_lik=-0.13 mean_kl_div=0.24\n",
            "Epoch 220, Loss: 0.3746\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.96, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 0.97, F1-score = 0.97\n",
            "test : Label 0: Accuracy = 0.80, Precision = 0.65, Recall = 0.59, F1-score = 0.62\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.56, Recall = 0.61, F1-score = 0.58\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[6.7753e-07, 9.7700e-12],\n",
            "        [6.7753e-07, 9.7700e-12],\n",
            "        [1.1892e-02, 9.3295e-01],\n",
            "        [6.7753e-07, 9.7700e-12],\n",
            "        [9.8615e-01, 5.3384e-03]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.36 mean_log_lik=-0.12 mean_kl_div=0.24\n",
            "Epoch 230, Loss: 0.3571\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.97, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 0.98, F1-score = 0.98\n",
            "test : Label 0: Accuracy = 0.80, Precision = 0.66, Recall = 0.59, F1-score = 0.62\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.58, Recall = 0.59, F1-score = 0.58\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[3.3728e-07, 6.8158e-13],\n",
            "        [3.3728e-07, 6.8158e-13],\n",
            "        [1.0497e-02, 9.2076e-01],\n",
            "        [3.3728e-07, 6.8158e-13],\n",
            "        [9.9117e-01, 2.3979e-03]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.34 mean_log_lik=-0.11 mean_kl_div=0.24\n",
            "Epoch 240, Loss: 0.3437\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.97, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.66, Recall = 0.62, F1-score = 0.64\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.59, Recall = 0.60, F1-score = 0.59\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[8.3657e-08, 7.5753e-14],\n",
            "        [8.3657e-08, 7.5753e-14],\n",
            "        [7.4804e-03, 9.2698e-01],\n",
            "        [8.3657e-08, 7.5753e-14],\n",
            "        [9.9428e-01, 1.4766e-03]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.33 mean_log_lik=-0.10 mean_kl_div=0.23\n",
            "Epoch 250, Loss: 0.3328\n",
            "train : Label 0: Accuracy = 0.98, Precision = 0.94, Recall = 0.98, F1-score = 0.96\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 0.98, F1-score = 0.98\n",
            "test : Label 0: Accuracy = 0.80, Precision = 0.66, Recall = 0.61, F1-score = 0.64\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.59, Recall = 0.60, F1-score = 0.59\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[4.3361e-08, 2.5101e-14],\n",
            "        [4.3361e-08, 2.5101e-14],\n",
            "        [7.8002e-03, 9.4307e-01],\n",
            "        [4.3361e-08, 2.5101e-14],\n",
            "        [9.9621e-01, 1.0071e-03]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.32 mean_log_lik=-0.09 mean_kl_div=0.23\n",
            "Epoch 260, Loss: 0.3230\n",
            "train : Label 0: Accuracy = 0.98, Precision = 0.95, Recall = 0.98, F1-score = 0.96\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 0.99, F1-score = 0.98\n",
            "test : Label 0: Accuracy = 0.80, Precision = 0.65, Recall = 0.60, F1-score = 0.62\n",
            "test : Label 1: Accuracy = 0.83, Precision = 0.61, Recall = 0.63, F1-score = 0.62\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.3716e-08, 8.5116e-15],\n",
            "        [1.3716e-08, 8.5116e-15],\n",
            "        [4.7866e-03, 9.6117e-01],\n",
            "        [1.3716e-08, 8.5116e-15],\n",
            "        [9.9678e-01, 8.3646e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.31 mean_log_lik=-0.08 mean_kl_div=0.23\n",
            "Epoch 270, Loss: 0.3131\n",
            "train : Label 0: Accuracy = 0.98, Precision = 0.93, Recall = 0.98, F1-score = 0.96\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.80, Precision = 0.66, Recall = 0.59, F1-score = 0.62\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.58, Recall = 0.62, F1-score = 0.60\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[5.8506e-09, 2.1336e-15],\n",
            "        [5.8506e-09, 2.1336e-15],\n",
            "        [2.0537e-03, 9.8120e-01],\n",
            "        [5.8506e-09, 2.1336e-15],\n",
            "        [9.9545e-01, 1.8335e-03]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.30 mean_log_lik=-0.08 mean_kl_div=0.23\n",
            "Epoch 280, Loss: 0.3036\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.92, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 0.99, F1-score = 0.98\n",
            "test : Label 0: Accuracy = 0.80, Precision = 0.66, Recall = 0.61, F1-score = 0.64\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.58, Recall = 0.61, F1-score = 0.59\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[3.3204e-09, 9.4084e-16],\n",
            "        [3.3204e-09, 9.4084e-16],\n",
            "        [2.8650e-03, 9.6991e-01],\n",
            "        [3.3204e-09, 9.4084e-16],\n",
            "        [9.9876e-01, 3.1296e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.30 mean_log_lik=-0.07 mean_kl_div=0.22\n",
            "Epoch 290, Loss: 0.2972\n",
            "train : Label 0: Accuracy = 0.98, Precision = 0.93, Recall = 0.98, F1-score = 0.96\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.80, Precision = 0.66, Recall = 0.59, F1-score = 0.62\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.59, Recall = 0.63, F1-score = 0.61\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.8279e-09, 5.3298e-16],\n",
            "        [1.8279e-09, 5.3298e-16],\n",
            "        [1.0910e-03, 9.8836e-01],\n",
            "        [1.8279e-09, 5.3298e-16],\n",
            "        [9.9816e-01, 6.1112e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.29 mean_log_lik=-0.07 mean_kl_div=0.22\n",
            "Epoch 300, Loss: 0.2905\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.67, Recall = 0.63, F1-score = 0.65\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.58, Recall = 0.64, F1-score = 0.61\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.0349e-09, 2.1208e-16],\n",
            "        [1.0349e-09, 2.1208e-16],\n",
            "        [1.2089e-03, 9.9016e-01],\n",
            "        [1.0349e-09, 2.1208e-16],\n",
            "        [9.9803e-01, 7.4518e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.28 mean_log_lik=-0.07 mean_kl_div=0.22\n",
            "Epoch 310, Loss: 0.2846\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.67, Recall = 0.63, F1-score = 0.65\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.57, Recall = 0.61, F1-score = 0.59\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[5.5697e-10, 1.2504e-16],\n",
            "        [5.5697e-10, 1.2504e-16],\n",
            "        [9.9435e-04, 9.8953e-01],\n",
            "        [5.5697e-10, 1.2504e-16],\n",
            "        [9.9875e-01, 3.6437e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.28 mean_log_lik=-0.06 mean_kl_div=0.22\n",
            "Epoch 320, Loss: 0.2790\n",
            "train : Label 0: Accuracy = 0.98, Precision = 0.94, Recall = 0.98, F1-score = 0.96\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.67, Recall = 0.61, F1-score = 0.64\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.58, Recall = 0.61, F1-score = 0.60\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[2.6729e-10, 5.1326e-17],\n",
            "        [2.6729e-10, 5.1326e-17],\n",
            "        [4.6159e-04, 9.9636e-01],\n",
            "        [2.6729e-10, 5.1326e-17],\n",
            "        [9.9901e-01, 2.7524e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.27 mean_log_lik=-0.06 mean_kl_div=0.21\n",
            "Epoch 330, Loss: 0.2741\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.67, Recall = 0.62, F1-score = 0.65\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.57, Recall = 0.62, F1-score = 0.59\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.3749e-10, 2.9827e-17],\n",
            "        [1.3749e-10, 2.9827e-17],\n",
            "        [5.3318e-04, 9.9412e-01],\n",
            "        [1.3749e-10, 2.9827e-17],\n",
            "        [9.9845e-01, 5.0952e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.27 mean_log_lik=-0.06 mean_kl_div=0.21\n",
            "Epoch 340, Loss: 0.2700\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.67, Recall = 0.62, F1-score = 0.64\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.58, Recall = 0.62, F1-score = 0.60\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[5.2642e-11, 9.3594e-18],\n",
            "        [5.2642e-11, 9.3594e-18],\n",
            "        [3.7076e-04, 9.9475e-01],\n",
            "        [5.2642e-11, 9.3594e-18],\n",
            "        [9.9880e-01, 3.8093e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.27 mean_log_lik=-0.06 mean_kl_div=0.21\n",
            "Epoch 350, Loss: 0.2665\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.67, Recall = 0.61, F1-score = 0.64\n",
            "test : Label 1: Accuracy = 0.81, Precision = 0.57, Recall = 0.62, F1-score = 0.59\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[4.4761e-11, 2.2393e-17],\n",
            "        [4.4761e-11, 2.2393e-17],\n",
            "        [1.3909e-04, 9.9793e-01],\n",
            "        [4.4761e-11, 2.2393e-17],\n",
            "        [9.9842e-01, 7.2995e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.26 mean_log_lik=-0.06 mean_kl_div=0.21\n",
            "Epoch 360, Loss: 0.2623\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.67, Recall = 0.61, F1-score = 0.64\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.58, Recall = 0.63, F1-score = 0.60\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[9.7349e-12, 3.5400e-18],\n",
            "        [9.7349e-12, 3.5400e-18],\n",
            "        [4.1298e-04, 9.9628e-01],\n",
            "        [9.7349e-12, 3.5400e-18],\n",
            "        [9.9917e-01, 2.8004e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.26 mean_log_lik=-0.05 mean_kl_div=0.20\n",
            "Epoch 370, Loss: 0.2586\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.68, Recall = 0.62, F1-score = 0.65\n",
            "test : Label 1: Accuracy = 0.83, Precision = 0.60, Recall = 0.63, F1-score = 0.61\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[6.3805e-12, 4.1844e-18],\n",
            "        [6.3805e-12, 4.1844e-18],\n",
            "        [1.4992e-04, 9.9893e-01],\n",
            "        [6.3805e-12, 4.1844e-18],\n",
            "        [9.9952e-01, 9.8329e-05]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.25 mean_log_lik=-0.05 mean_kl_div=0.20\n",
            "Epoch 380, Loss: 0.2548\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.67, Recall = 0.63, F1-score = 0.65\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.59, Recall = 0.61, F1-score = 0.60\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[3.9560e-12, 1.4868e-18],\n",
            "        [3.9560e-12, 1.4868e-18],\n",
            "        [5.0714e-04, 9.9290e-01],\n",
            "        [3.9560e-12, 1.4868e-18],\n",
            "        [9.9936e-01, 2.4354e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.25 mean_log_lik=-0.05 mean_kl_div=0.20\n",
            "Epoch 390, Loss: 0.2514\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.68, Recall = 0.63, F1-score = 0.65\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.59, Recall = 0.62, F1-score = 0.60\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.6905e-12, 1.5822e-18],\n",
            "        [1.6905e-12, 1.5822e-18],\n",
            "        [2.2512e-04, 9.9660e-01],\n",
            "        [1.6905e-12, 1.5822e-18],\n",
            "        [9.9965e-01, 6.9672e-05]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.25 mean_log_lik=-0.05 mean_kl_div=0.20\n",
            "Epoch 400, Loss: 0.2484\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.68, Recall = 0.61, F1-score = 0.65\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.58, Recall = 0.64, F1-score = 0.61\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.6050e-12, 2.0347e-18],\n",
            "        [1.6050e-12, 2.0347e-18],\n",
            "        [6.5205e-05, 9.9919e-01],\n",
            "        [1.6050e-12, 2.0347e-18],\n",
            "        [9.9939e-01, 1.8876e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.24 mean_log_lik=-0.05 mean_kl_div=0.19\n",
            "Epoch 410, Loss: 0.2449\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.68, Recall = 0.61, F1-score = 0.64\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.59, Recall = 0.64, F1-score = 0.62\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.1909e-12, 2.2879e-18],\n",
            "        [1.1909e-12, 2.2879e-18],\n",
            "        [5.0912e-05, 9.9948e-01],\n",
            "        [1.1909e-12, 2.2879e-18],\n",
            "        [9.9977e-01, 5.8239e-05]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.24 mean_log_lik=-0.05 mean_kl_div=0.19\n",
            "Epoch 420, Loss: 0.2421\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.68, Recall = 0.62, F1-score = 0.65\n",
            "test : Label 1: Accuracy = 0.83, Precision = 0.60, Recall = 0.63, F1-score = 0.61\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[2.3211e-13, 9.3776e-19],\n",
            "        [2.3211e-13, 9.3776e-19],\n",
            "        [3.2909e-04, 9.9807e-01],\n",
            "        [2.3211e-13, 9.3776e-19],\n",
            "        [9.9992e-01, 1.0023e-05]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.24 mean_log_lik=-0.05 mean_kl_div=0.19\n",
            "Epoch 430, Loss: 0.2390\n",
            "train : Label 0: Accuracy = 0.98, Precision = 0.93, Recall = 0.98, F1-score = 0.96\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.82, Precision = 0.69, Recall = 0.64, F1-score = 0.66\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.59, Recall = 0.63, F1-score = 0.61\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.6930e-13, 8.3572e-19],\n",
            "        [1.6930e-13, 8.3572e-19],\n",
            "        [4.1286e-04, 9.9224e-01],\n",
            "        [1.6930e-13, 8.3572e-19],\n",
            "        [9.9952e-01, 7.9338e-05]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.24 mean_log_lik=-0.05 mean_kl_div=0.19\n",
            "Epoch 440, Loss: 0.2355\n",
            "train : Label 0: Accuracy = 0.97, Precision = 0.93, Recall = 0.98, F1-score = 0.95\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.68, Recall = 0.64, F1-score = 0.66\n",
            "test : Label 1: Accuracy = 0.83, Precision = 0.61, Recall = 0.64, F1-score = 0.63\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.0030e-13, 5.9345e-19],\n",
            "        [1.0030e-13, 5.9345e-19],\n",
            "        [9.1317e-05, 9.9826e-01],\n",
            "        [1.0030e-13, 5.9345e-19],\n",
            "        [9.9990e-01, 1.9324e-05]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.23 mean_log_lik=-0.05 mean_kl_div=0.18\n",
            "Epoch 450, Loss: 0.2325\n",
            "train : Label 0: Accuracy = 0.99, Precision = 1.00, Recall = 0.98, F1-score = 0.99\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.82, Precision = 0.69, Recall = 0.64, F1-score = 0.66\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.58, Recall = 0.62, F1-score = 0.60\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[8.0508e-14, 9.1575e-19],\n",
            "        [8.0508e-14, 9.1575e-19],\n",
            "        [7.6582e-05, 9.9889e-01],\n",
            "        [8.0508e-14, 9.1575e-19],\n",
            "        [9.9986e-01, 2.6760e-05]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.23 mean_log_lik=-0.05 mean_kl_div=0.18\n",
            "Epoch 460, Loss: 0.2296\n",
            "train : Label 0: Accuracy = 0.98, Precision = 0.96, Recall = 0.98, F1-score = 0.97\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.82, Precision = 0.69, Recall = 0.65, F1-score = 0.67\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.59, Recall = 0.64, F1-score = 0.61\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[3.5171e-14, 5.1401e-19],\n",
            "        [3.5171e-14, 5.1401e-19],\n",
            "        [4.7704e-05, 9.9945e-01],\n",
            "        [3.5171e-14, 5.1401e-19],\n",
            "        [9.9956e-01, 1.6228e-04]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.23 mean_log_lik=-0.05 mean_kl_div=0.18\n",
            "Epoch 470, Loss: 0.2266\n",
            "train : Label 0: Accuracy = 0.99, Precision = 0.98, Recall = 0.98, F1-score = 0.98\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.82, Precision = 0.69, Recall = 0.64, F1-score = 0.66\n",
            "test : Label 1: Accuracy = 0.83, Precision = 0.60, Recall = 0.63, F1-score = 0.62\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[2.4750e-14, 4.2518e-19],\n",
            "        [2.4750e-14, 4.2518e-19],\n",
            "        [2.1140e-05, 9.9971e-01],\n",
            "        [2.4750e-14, 4.2518e-19],\n",
            "        [9.9990e-01, 1.8076e-05]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.22 mean_log_lik=-0.05 mean_kl_div=0.18\n",
            "Epoch 480, Loss: 0.2242\n",
            "train : Label 0: Accuracy = 0.99, Precision = 0.98, Recall = 0.98, F1-score = 0.98\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.68, Recall = 0.63, F1-score = 0.66\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.59, Recall = 0.61, F1-score = 0.60\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[1.5459e-14, 9.4266e-19],\n",
            "        [1.5459e-14, 9.4266e-19],\n",
            "        [2.0210e-05, 9.9976e-01],\n",
            "        [1.5459e-14, 9.4266e-19],\n",
            "        [9.9992e-01, 1.5945e-05]], dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "ELBO=-0.22 mean_log_lik=-0.05 mean_kl_div=0.17\n",
            "Epoch 490, Loss: 0.2216\n",
            "train : Label 0: Accuracy = 0.98, Precision = 0.93, Recall = 0.98, F1-score = 0.96\n",
            "train : Label 1: Accuracy = 0.99, Precision = 0.98, Recall = 1.00, F1-score = 0.99\n",
            "test : Label 0: Accuracy = 0.81, Precision = 0.68, Recall = 0.63, F1-score = 0.65\n",
            "test : Label 1: Accuracy = 0.82, Precision = 0.59, Recall = 0.63, F1-score = 0.61\n",
            "true tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [1., 0.]], dtype=torch.float64) pred tensor([[8.1459e-15, 5.7172e-19],\n",
            "        [8.1459e-15, 5.7172e-19],\n",
            "        [6.5291e-05, 9.9686e-01],\n",
            "        [8.1459e-15, 5.7172e-19],\n",
            "        [9.9993e-01, 1.1229e-05]], dtype=torch.float64, grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train the model\n",
        "n_epochs = 500  # Set to a small value for this example\n",
        "\n",
        "data_size = X.shape[0]\n",
        "for epoch in range(n_epochs):\n",
        "    verbose = (epoch%10==0)\n",
        "\n",
        "    for X_batch, y_batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model_logisticvi.train_loss(X_batch, y_batch, data_size, verbose=verbose)\n",
        "        loss.backward()\n",
        "        # for i in model_logisticvi.params:\n",
        "        #   print(i.grad)\n",
        "        optimizer.step()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "        evaluate(model_logisticvi, X, y, prefix=\"train\")\n",
        "        f1_test = evaluate(model_logisticvi, X_test, y_test, prefix=\"test\")\n",
        "        f1_test = sum(f1_test) / len(f1_test)\n",
        "        if f1_test > f1_thres:\n",
        "          f1_thres = f1_test\n",
        "          model_logisticvi_best = copy.deepcopy(model_logisticvi)\n",
        "          torch.save(model_logisticvi_best.backbone.state_dict(), \"./logisticvi_backbone_circlessquares.pt\")\n",
        "          for i, m in enumerate(model_logisticvi_best.m_list):\n",
        "            torch.save(m, f\"./logisticvi_att_{i}.pt\")\n",
        "        n_test_data_pred = 5\n",
        "        preds = model_logisticvi.predict(X_test[0:n_test_data_pred])\n",
        "        print(\"true\", y_test[0:n_test_data_pred], \"pred\", preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qTUPmk5l2yn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1bHLZDsl3bZ"
      },
      "source": [
        "### Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCcgs-UUl2m0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfSNVm78l2Yk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdPYcQfaigrg"
      },
      "source": [
        "# [WIP] Real-life dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMjy-09Vh58B"
      },
      "source": [
        "See datasets @ https://www.uco.es/kdis/mllresources/#Corel16kDesc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5ml1m0Sh642"
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchtext nltk\n",
        "# # !pip install --upgrade torch torchtext nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoO5jLWFx26j"
      },
      "outputs": [],
      "source": [
        "# import nltk\n",
        "\n",
        "# nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fKEc_ZfiflV"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from torch.utils.data import DataLoader, Dataset\n",
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "# from torchtext.vocab import GloVe\n",
        "# from nltk.corpus import reuters\n",
        "# import nltk\n",
        "# nltk.download('reuters')\n",
        "# nltk.download('punkt')\n",
        "\n",
        "# # Load the Reuters dataset\n",
        "# categories = reuters.categories()  # list of all categories (multi-labels)\n",
        "# documents = reuters.fileids()\n",
        "\n",
        "# # Split into train and test sets\n",
        "# train_docs = [doc for doc in documents if doc.startswith(\"train\")]\n",
        "# test_docs = [doc for doc in documents if doc.startswith(\"test\")]\n",
        "\n",
        "# # Tokenize and preprocess documents\n",
        "# def tokenize_and_preprocess(doc_id):\n",
        "#     tokens = nltk.word_tokenize(reuters.raw(doc_id))\n",
        "#     return tokens\n",
        "\n",
        "# train_tokens = [tokenize_and_preprocess(doc_id) for doc_id in train_docs]\n",
        "# test_tokens = [tokenize_and_preprocess(doc_id) for doc_id in test_docs]\n",
        "\n",
        "# # Create multi-labels for documents\n",
        "# def get_labels(doc_id):\n",
        "#     labels = torch.zeros(len(categories))\n",
        "#     for category in reuters.categories(doc_id):\n",
        "#         labels[categories.index(category)] = 1.0\n",
        "#     return labels\n",
        "\n",
        "# train_labels = [get_labels(doc_id) for doc_id in train_docs]\n",
        "# test_labels = [get_labels(doc_id) for doc_id in test_docs]\n",
        "\n",
        "# # Build Vocabulary and Embeddings\n",
        "# glove = GloVe(name='6B', dim=100)\n",
        "# def vectorize(tokens):\n",
        "#     vectors = [glove[token] for token in tokens if token in glove.stoi]\n",
        "#     return torch.stack(vectors) if vectors else torch.empty(0, 100)\n",
        "\n",
        "# train_vectors = [vectorize(tokens) for tokens in train_tokens]\n",
        "# test_vectors = [vectorize(tokens) for tokens in test_tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNfScqM6in0P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}